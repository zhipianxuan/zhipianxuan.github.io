<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Lee_yl&#39;s blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Lee_yl&#39;s blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Lee_yl&#39;s blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>Lee_yl's blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Lee_yl's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/DataFrame/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/DataFrame/" itemprop="url">DataFrame</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-03-12T00:00:00+08:00">
                2023-03-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文仅做学习总结，如有侵权立删</p>
<h1 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h1><h2 id="一、Spark-SQL"><a href="#一、Spark-SQL" class="headerlink" title="一、Spark SQL"></a>一、Spark SQL</h2><blockquote>
<p><strong>Spark SQL用于对结构化数据进行处理，它提供了DataFrame的抽象</strong>，作为分布式平台数据查询引擎，可以在此组件上构建大数据仓库。</p>
<p><strong>DataFrame是一个分布式数据集，在概念上类似于传统数据库的表结构</strong>，数据被组织成命名的列，DataFrame的数据源可以是结构化的数据文件，也可以是Hive中的表或外部数据库，也还可以是现有的RDD。</p>
<p>DataFrame的一个主要优点是，Spark引擎一开始就构建了一个逻辑执行计划，而且执行生成的代码是基于成本优化程序确定的物理计划。与Java或者Scala相比，<strong>Python中的RDD是非常慢的，而DataFrame的引入则使性能在各种语言中都保持稳定。</strong></p>
</blockquote>
<h2 id="二、初始化"><a href="#二、初始化" class="headerlink" title="二、初始化"></a>二、初始化</h2><blockquote>
<p>在过去，你可能会使用SparkConf、SparkContext、SQLContext和HiveContext来分别执行配置、Spark环境、SQL环境和Hive环境的各种Spark查询。</p>
<p><strong>SparkSession现在是读取数据、处理元数据、配置会话和管理集群资源的入口。SparkSession本质上是这些环境的组合</strong>，包括StreamingContext。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line">spark=SparkSession \</span><br><span class="line">   .builder \</span><br><span class="line">   .appName(<span class="string">'test'</span>) \</span><br><span class="line">   .config(<span class="string">'master'</span>,<span class="string">'yarn'</span>) \</span><br><span class="line">   .getOrCreate()</span><br></pre></td></tr></table></figure>
<p>Spark 交互式环境下，默认已经创建了名为 spark 的 SparkSession 对象，不需要自行创建。</p>
<p><strong>从RDD创建DataFrame</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 推断schema</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> Row</span><br><span class="line">lines = sc.textFile(<span class="string">"users.txt"</span>)</span><br><span class="line">parts = lines.map(<span class="keyword">lambda</span> l: l.split(<span class="string">","</span>))</span><br><span class="line">data = parts.map(<span class="keyword">lambda</span> p: Row(name=p[<span class="number">0</span>],age=p[<span class="number">1</span>],city=p[<span class="number">2</span>]))</span><br><span class="line">df=createDataFrame(data)</span><br><span class="line"><span class="comment"># 指定schema</span></span><br><span class="line">data = parts.map(<span class="keyword">lambda</span> p: Row(name=p[<span class="number">0</span>],age=int(p[<span class="number">1</span>]),city=p[<span class="number">2</span>]))</span><br><span class="line">df=createDataFrame(data)</span><br><span class="line"><span class="comment"># StructType指定schema</span></span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line">schema = StructType([</span><br><span class="line">    StructField(<span class="string">'name'</span>,StringType(),<span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">'age'</span>,LongType(),<span class="literal">True</span>),</span><br><span class="line">    StructField(<span class="string">'city'</span>,StringType(),<span class="literal">True</span>)</span><br><span class="line">    ])</span><br><span class="line">df=createDataFrame(parts, schema)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>StructField包括以下方面的内容：<br>name：字段名<br>dataType：数据类型<br>nullable：此字段的值是否为空</p>
</blockquote>
<p><strong>从文件系统创建DataFrame</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df = spark.read.json(<span class="string">"customer.json"</span>)</span><br><span class="line">df = spark.read.load(<span class="string">"customer.json"</span>, format=<span class="string">"json"</span>)</span><br><span class="line">df = spark.read.load(<span class="string">"users.parquet"</span>)</span><br><span class="line">df = spark.read.text(<span class="string">"users.txt"</span>)</span><br></pre></td></tr></table></figure>
<p><strong>输出和保存</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df.rdd <span class="comment"># df转化为RDD</span></span><br><span class="line">df.toJSON() <span class="comment"># df转化为RDD字符串</span></span><br><span class="line">df.toPandas() <span class="comment"># df转化为pandas</span></span><br><span class="line">df.write.save(<span class="string">"customer.json"</span>, format=<span class="string">"json"</span>)</span><br><span class="line">df.write.save(<span class="string">"users.parquet"</span>)</span><br><span class="line">df.write.json(<span class="string">"users.json"</span>)</span><br><span class="line">df.write.text(<span class="string">"users.txt"</span>)</span><br></pre></td></tr></table></figure>
<p><strong>数据库读写</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df = spark.sql(<span class="string">'select name,age,city from users'</span>) </span><br><span class="line">df.createOrReplaceTempView(name) <span class="comment"># 创建临时视图</span></span><br><span class="line">df.write.saveAsTable(name,mode=<span class="string">'overwrite'</span>,partitionBy=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<p><strong>操作hive表</strong><br><code>df.write</code> 有两种方法操作hive表</p>
<ul>
<li><code>saveAsTable()</code><br>如果hive中不存在该表，则spark会自动创建此表匹。<br>如果表已存在，则匹配插入数据和原表 schema(数据格式，分区等)，只要有区别就会报错<br>若是分区表可以调用<code>partitionBy</code>指定分区，使用<code>mode</code>方法调整数据插入方式：</li>
</ul>
<blockquote>
<p>Specifies the behavior when data or table already exists. Options include:</p>
<ul>
<li><code>overwrite</code>: 覆盖原始数据(包括原表的格式，注释等)</li>
<li><code>append</code>: 追加数据(需要严格匹配)</li>
<li><code>ignore</code>: ignore the operation (i.e. no-op).</li>
<li><code>error</code> or <code>errorifexists</code>: default option, throw an exception at runtime.</li>
</ul>
</blockquote>
<ul>
<li><code>df.write.partitionBy(&#39;dt&#39;).mode(&#39;append&#39;).saveAsTable(&#39;tb2&#39;)</code></li>
<li><code>insertInto()</code></li>
</ul>
<p>无关schema，只按数据的顺序插入，如果原表不存在则会报错<br>对于分区表，先开启Hive动态分区，则不需要指定分区字段，如果有一个分区，那么默认为数据中最后一列为分区字段，有两个分区则为最后两列为分区字段，以此类推</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sqlContext.setConf(<span class="string">"hive.exec.dynamic.partition"</span>, <span class="string">"true"</span>)</span><br><span class="line">sqlContext.setConf(<span class="string">"hive.exec.dynamic.partition.mode"</span>, <span class="string">"nonstrict"</span>)</span><br><span class="line">df.write.insertInto(<span class="string">'tb2'</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>同样也可以先开启Hive动态分区，用SQL语句直接运行<br><code>sql(&quot;insert into tb2 select * from tb1&quot;)</code></li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:left">DataFrame信息</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>df.show(n)</code></td>
<td style="text-align:left">预览前 n 行数据</td>
</tr>
<tr>
<td style="text-align:left"><code>df.collect()</code></td>
<td style="text-align:left">列表形式返回</td>
</tr>
<tr>
<td style="text-align:left"><code>df.dtypes</code></td>
<td style="text-align:left">列名与数据类型</td>
</tr>
<tr>
<td style="text-align:left"><code>df.head(n)</code></td>
<td style="text-align:left">返回前 n 行数据</td>
</tr>
<tr>
<td style="text-align:left"><code>df.first()</code></td>
<td style="text-align:left">返回第 1 行数据</td>
</tr>
<tr>
<td style="text-align:left"><code>df.take(n)</code></td>
<td style="text-align:left">返回前 n 行数据</td>
</tr>
<tr>
<td style="text-align:left"><code>df.printSchema()</code></td>
<td style="text-align:left">打印模式信息</td>
</tr>
<tr>
<td style="text-align:left"><code>df.columns</code></td>
<td style="text-align:left">列名</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left">查询语句</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>df.select(*cols)</code></td>
<td style="text-align:left"><code>SELECT</code> in SQL</td>
</tr>
<tr>
<td style="text-align:left"><code>df.union(other)</code></td>
<td style="text-align:left"><code>UNION ALL</code> in SQL</td>
</tr>
<tr>
<td style="text-align:left"><code>df.when(condition,value)</code></td>
<td style="text-align:left"><code>CASE WHEN</code> in SQL</td>
</tr>
<tr>
<td style="text-align:left"><code>df.alias(*alias,**kwargs)</code></td>
<td style="text-align:left"><code>as</code> in SQL</td>
</tr>
<tr>
<td style="text-align:left"><code>F.cast(dataType)</code></td>
<td style="text-align:left">数据类型转换（函数）</td>
</tr>
<tr>
<td style="text-align:left"><code>F.lit(col)</code></td>
<td style="text-align:left">常数列（函数）</td>
</tr>
<tr>
<td style="text-align:left">selectExpr</td>
<td style="text-align:left">表查询</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> functions <span class="keyword">as</span> F</span><br><span class="line">df.select(<span class="string">'*'</span>)</span><br><span class="line">df.select(<span class="string">'name'</span>,<span class="string">'age'</span>) <span class="comment"># 字段名查询</span></span><br><span class="line">df.select([<span class="string">'name'</span>,<span class="string">'age'</span>]) <span class="comment"># 字段列表查询</span></span><br><span class="line">df.select(df[<span class="string">'name'</span>],df[<span class="string">'age'</span>]+<span class="number">1</span>) <span class="comment"># 表达式查询</span></span><br><span class="line">df.select(<span class="string">'name'</span>,df.mobile.alias(<span class="string">'phone'</span>)) <span class="comment"># 重命名列</span></span><br><span class="line">df.select(<span class="string">'name'</span>,<span class="string">'age'</span>,F.lit(<span class="string">'2020'</span>).alias(<span class="string">'update'</span>))  <span class="comment"># 常数</span></span><br><span class="line">df.select(<span class="string">'name'</span>,</span><br><span class="line">          F.when(df.age &gt; <span class="number">100</span>,<span class="number">100</span>)</span><br><span class="line">           .when(df.age &lt; <span class="number">0</span>,<span class="number">-1</span>)</span><br><span class="line">           .otherwise(df.age)</span><br><span class="line">          ).show()</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> *</span><br><span class="line">df.select(<span class="string">'name'</span>,df.age.cast(<span class="string">'float'</span>))</span><br><span class="line">df.select(<span class="string">'name'</span>,df.age.cast(FloatType()))</span><br><span class="line"><span class="comment"># selectExpr接口支持并行计算</span></span><br><span class="line">expr=[<span class="string">'count(&#123;&#125;)'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> df.columns]</span><br><span class="line">df.selectExpr(*expr).collect()[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#表查询selectExpr,可以使用UDF函数，指定别名等</span></span><br><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line">spark.udf.register(<span class="string">"getBirthYear"</span>,<span class="keyword">lambda</span> age:datetime.datetime.now().year-age)</span><br><span class="line">dftest = df.selectExpr(<span class="string">"name"</span>, <span class="string">"getBirthYear(age) as birth_year"</span> , <span class="string">"UPPER(gender) as gender"</span> )</span><br><span class="line">dftest.show()</span><br><span class="line"></span><br><span class="line">---------------------------</span><br><span class="line"><span class="comment">#窗口函数</span></span><br><span class="line"></span><br><span class="line">df = spark.createDataFrame([(<span class="string">"LiLei"</span>,<span class="number">78</span>,<span class="string">"class1"</span>),(<span class="string">"HanMeiMei"</span>,<span class="number">87</span>,<span class="string">"class1"</span>),</span><br><span class="line">                           (<span class="string">"DaChui"</span>,<span class="number">65</span>,<span class="string">"class2"</span>),(<span class="string">"RuHua"</span>,<span class="number">55</span>,<span class="string">"class2"</span>)]) \</span><br><span class="line">    .toDF(<span class="string">"name"</span>,<span class="string">"score"</span>,<span class="string">"class"</span>)</span><br><span class="line"></span><br><span class="line">df.show()</span><br><span class="line">dforder = df.selectExpr(<span class="string">"name"</span>,<span class="string">"score"</span>,<span class="string">"class"</span>,</span><br><span class="line">         <span class="string">"row_number() over (partition by class order by score desc) as order"</span>)</span><br><span class="line"></span><br><span class="line">dforder.show()</span><br><span class="line">+---------+-----+------+</span><br><span class="line">|     name|score| <span class="class"><span class="keyword">class</span>|</span></span><br><span class="line"><span class="class">+---------+-----+------+</span></span><br><span class="line"><span class="class">|    <span class="title">LiLei</span>|   78|<span class="title">class1</span>|</span></span><br><span class="line"><span class="class">|<span class="title">HanMeiMei</span>|   87|<span class="title">class1</span>|</span></span><br><span class="line"><span class="class">|   <span class="title">DaChui</span>|   65|<span class="title">class2</span>|</span></span><br><span class="line"><span class="class">|    <span class="title">RuHua</span>|   55|<span class="title">class2</span>|</span></span><br><span class="line"><span class="class">+---------+-----+------+</span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class">+---------+-----+------+-----+</span></span><br><span class="line"><span class="class">|     <span class="title">name</span>|<span class="title">score</span>| <span class="title">class</span>|<span class="title">order</span>|</span></span><br><span class="line"><span class="class">+---------+-----+------+-----+</span></span><br><span class="line"><span class="class">|   <span class="title">DaChui</span>|   65|<span class="title">class2</span>|    1|</span></span><br><span class="line"><span class="class">|    <span class="title">RuHua</span>|   55|<span class="title">class2</span>|    2|</span></span><br><span class="line"><span class="class">|<span class="title">HanMeiMei</span>|   87|<span class="title">class1</span>|    1|</span></span><br><span class="line"><span class="class">|    <span class="title">LiLei</span>|   78|<span class="title">class1</span>|    2|</span></span><br><span class="line"><span class="class">+---------+-----+------+-----+</span></span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">排序</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>df.sort(*col,**kwargs)</code></td>
<td style="text-align:left">排序</td>
</tr>
<tr>
<td style="text-align:left"><code>df.orderBy(*col,**kwargs)</code></td>
<td style="text-align:left">排序(用法同sort)</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df.sort(df.age.desc()).show()</span><br><span class="line">df.sort(<span class="string">'age'</span>,ascending=<span class="literal">True</span>).show()</span><br><span class="line">df.sort(desc(<span class="string">'age'</span>),<span class="string">'name'</span>).show()</span><br><span class="line">df.sort([<span class="string">'age'</span>,<span class="string">'name'</span>],ascending=[<span class="number">0</span>,<span class="number">1</span>]).show()</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">筛选方法</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>df.filter(condition)</code></td>
<td style="text-align:left">筛选</td>
</tr>
<tr>
<td style="text-align:left"><code>column.isin(*cols)</code></td>
<td style="text-align:left"><code>in (...)</code></td>
</tr>
<tr>
<td style="text-align:left"><code>column.like(pattern)</code></td>
<td style="text-align:left">SQL通配符匹配</td>
</tr>
<tr>
<td style="text-align:left"><code>column.rlike(pattern)</code></td>
<td style="text-align:left">正则表达式匹配</td>
</tr>
<tr>
<td style="text-align:left"><code>column.startswith(pattern)</code></td>
<td style="text-align:left">匹配开始</td>
</tr>
<tr>
<td style="text-align:left"><code>column.endswith(pattern)</code></td>
<td style="text-align:left">匹配结尾</td>
</tr>
<tr>
<td style="text-align:left"><code>column.substr(start,length)</code></td>
<td style="text-align:left">截取字符串</td>
</tr>
<tr>
<td style="text-align:left"><code>column.between(lower,upper)</code></td>
<td style="text-align:left"><code>between ... and ...</code></td>
</tr>
<tr>
<td style="text-align:left">column.where</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df.filter(<span class="string">"age = 22"</span>).show()</span><br><span class="line">df.filter(df.age == <span class="number">22</span>).show()</span><br><span class="line">df.select(df[<span class="string">'age'</span>] == <span class="number">22</span>).show()</span><br><span class="line">df.select(df.name.isin(<span class="string">'Bill'</span>,<span class="string">'Elon'</span>)).show()</span><br><span class="line">df.filter(<span class="string">"name like Elon%"</span>).show()</span><br><span class="line">df.filter(df.name.rlike(<span class="string">"Musk$"</span>).show()</span><br><span class="line">          </span><br><span class="line">df.where(<span class="string">"gender='male' and age &gt; 15"</span>).show()</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">统计信息</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>df.describe()</code></td>
<td style="text-align:left">描述性统计</td>
</tr>
<tr>
<td style="text-align:left"><code>df.count()</code></td>
<td style="text-align:left">行数</td>
</tr>
<tr>
<td style="text-align:left"><code>df.approxQuantile(col,prob,relativeError)</code></td>
<td style="text-align:left">百分位数</td>
</tr>
<tr>
<td style="text-align:left"><code>df.corr(col1,col2,method=None)</code></td>
<td style="text-align:left">相关系数</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 异常值处理</span></span><br><span class="line">bounds = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> df.columns:</span><br><span class="line">    quantiles = df.approxQuantile(col,[<span class="number">0.25</span>,<span class="number">0.75</span>],<span class="number">0.05</span>)</span><br><span class="line">    <span class="comment"># 第三个参数relativeError代表可接受的错误程度，越小精度越高</span></span><br><span class="line">    IQR = quantiles[<span class="number">1</span>] - quantiles[<span class="number">0</span>]</span><br><span class="line">    bounds[col] = [quantiles[<span class="number">0</span>]<span class="number">-1.5</span>*IQR, quantiles[<span class="number">1</span>]+<span class="number">1.5</span>*IQR]</span><br><span class="line">    <span class="comment"># bounds保存了每个特征的上下限</span></span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">分组和聚合</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>df.groupBy(*cols)</code></td>
<td style="text-align:left">分组，返回GroupedData</td>
</tr>
<tr>
<td style="text-align:left"><code>groupedData.count()</code></td>
<td style="text-align:left">计数</td>
</tr>
<tr>
<td style="text-align:left"><code>groupedData.sum(*cols)</code></td>
<td style="text-align:left">求和</td>
</tr>
<tr>
<td style="text-align:left"><code>groupedData.avg(*cols)</code></td>
<td style="text-align:left">平均值</td>
</tr>
<tr>
<td style="text-align:left"><code>groupedData.mean(*cols)</code></td>
<td style="text-align:left">平均值</td>
</tr>
<tr>
<td style="text-align:left"><code>groupedData.max(*cols)</code></td>
<td style="text-align:left">最大值</td>
</tr>
<tr>
<td style="text-align:left"><code>groupedData.min(*cols)</code></td>
<td style="text-align:left">最小值</td>
</tr>
<tr>
<td style="text-align:left"><code>groupedData.agg(*exprs)</code></td>
<td style="text-align:left">应用表达式</td>
</tr>
</tbody>
</table>
<blockquote>
<p> 聚合函数还包括 countDistinct, kurtosis, skewness, stddev, sumDistinct, variance 等</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">df.groupBy(<span class="string">'city'</span>).count().collect()</span><br><span class="line">df.groupBy(df.city).avg(<span class="string">'age'</span>).collect()</span><br><span class="line">df.groupBy(<span class="string">'city'</span>,df.age).count().collect()</span><br><span class="line">df.groupBy(<span class="string">'city'</span>).agg(&#123;<span class="string">'age'</span>:<span class="string">'mean'</span>&#125;).collect() <span class="comment"># 字典形式给出</span></span><br><span class="line">df.groupBy(<span class="string">'city'</span>).agg(&#123;<span class="string">'*'</span>:<span class="string">'count'</span>&#125;).collect() </span><br><span class="line">df.groupBy(<span class="string">'city'</span>).agg(F.mean(df.age)).collect() </span><br><span class="line"><span class="comment"># groupBy + collect_list</span></span><br><span class="line">df.groupBy(<span class="string">"gender"</span>).agg(F.expr(<span class="string">"avg(age)"</span>),F.expr(<span class="string">"collect_list(name)"</span>)).show()</span><br><span class="line">+------+--------+------------------+</span><br><span class="line">|gender|avg(age)|collect_list(name)|</span><br><span class="line">+------+--------+------------------+</span><br><span class="line">|  null|    <span class="number">16.0</span>|           [RuHua]|</span><br><span class="line">|female|    <span class="number">16.0</span>|       [HanMeiMei]|</span><br><span class="line">|  male|    <span class="number">16.0</span>|   [LiLei, DaChui]|</span><br><span class="line">+------+--------+------------------+</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">去重</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>df.distinct()</code></td>
<td style="text-align:left">唯一值</td>
</tr>
<tr>
<td style="text-align:left"><code>df.dropDuplicates(subset=None)</code></td>
<td style="text-align:left">删除重复项</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left">添加、修改、删除列</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>df.withColumnRenamed(existing,new)</code></td>
<td style="text-align:left">重命名</td>
</tr>
<tr>
<td style="text-align:left"><code>df.withColumn(colname,new)</code></td>
<td style="text-align:left">修改列</td>
</tr>
<tr>
<td style="text-align:left"><code>df.drop(*cols)</code></td>
<td style="text-align:left">删除列</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df=df.withColumn(<span class="string">'age'</span>,df.age+<span class="number">1</span>)</span><br><span class="line">df=df.drop(<span class="string">'age'</span>)</span><br><span class="line">df=df.drop(df.age)</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">缺失值处理</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>df.na.fill(value,subset=None)</code></td>
<td style="text-align:left">缺失值填充</td>
</tr>
<tr>
<td style="text-align:left"><code>df.na.drop(how=&#39;any&#39;,thresh=None,subset=None)</code></td>
<td style="text-align:left">缺失值删除</td>
</tr>
<tr>
<td style="text-align:left"><code>df.na.replace(to_teplace,value,subset=None)</code></td>
<td style="text-align:left">替换</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df=df.na.fill(<span class="number">0</span>)</span><br><span class="line">df=df.na.fill(&#123;<span class="string">'age'</span>:<span class="number">50</span>,<span class="string">'name'</span>:<span class="string">'unknow'</span>&#125;)</span><br><span class="line">df=df.na.drop()</span><br><span class="line">df=df.na.replace([<span class="string">'Alice'</span>,<span class="string">'Bob'</span>],[<span class="string">'A'</span>,<span class="string">'B'</span>],<span class="string">'name'</span>)</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">分区和缓存</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>df.repartition(n)</code></td>
<td style="text-align:left">将df拆分为10个分区</td>
</tr>
<tr>
<td style="text-align:left"><code>df.coalesce(n)</code></td>
<td style="text-align:left">将df合并为n个分区</td>
</tr>
<tr>
<td style="text-align:left"><code>df.cache()</code></td>
<td style="text-align:left">缓存</td>
</tr>
</tbody>
</table>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/理解RDD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/理解RDD/" itemprop="url">RDD</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-03-11T00:00:00+08:00">
                2023-03-11
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文仅做学习总结，如有侵权立删</p>
<h1 id="一、理解RDD"><a href="#一、理解RDD" class="headerlink" title="一、理解RDD"></a>一、理解RDD</h1><blockquote>
<p> RDD可以被抽象地理解为一个大的数组，但是这个数组是分布在集群上的。</p>
<p><img src="..\imgs\RDD的理解.jpg" alt></p>
</blockquote>
<h1 id="二、RDD的生命周期"><a href="#二、RDD的生命周期" class="headerlink" title="二、RDD的生命周期"></a>二、RDD的生命周期</h1><p>创建—变换—动作（结束）</p>
<h1 id="三、RDD依赖"><a href="#三、RDD依赖" class="headerlink" title="三、RDD依赖"></a>三、RDD依赖</h1><p>1、窄依赖（RDD）—–原地变换，不需要shuffle【即各个RDD之间不需要统计】</p>
<p><img src="..\imgs\RDD1.jpg" alt></p>
<p>2、宽依赖（RDD）—–需要shuffle，与其他RDD交换资料，时间消耗长。</p>
<p><img src="..\imgs\RDD2.jpg" alt></p>
<p>3、任务优化，如</p>
<p><img src="..\imgs\RDD3.jpg" alt></p>
<h1 id="四、RDD的基本操作"><a href="#四、RDD的基本操作" class="headerlink" title="四、RDD的基本操作"></a>四、RDD的基本操作</h1><p>RDD可以有两种计算操作算子：Transformation（变换）与Action（行动）。</p>
<p><img src="..\imgs\RDD4.jpg" alt></p>
<h2 id="1、基本的RDD"><a href="#1、基本的RDD" class="headerlink" title="1、基本的RDD"></a>1、基本的RDD</h2><p>（1）建立RDD</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wordsList =  [<span class="string">'cat'</span>,<span class="string">'ele'</span>,<span class="string">'rat'</span>,<span class="string">'rat'</span>,<span class="string">'cat'</span>]</span><br><span class="line">wordsRDD =  sc.parallelize(wordsList , <span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>   #建立RDD   <code>wordsList =   [&#39;cat&#39;,&#39;ele&#39;,&#39;rat&#39;,&#39;rat&#39;,&#39;cat&#39;]</code>   <code>wordsRDD =   sc.parallelize(wordsList , 4)</code>   </p>
<p>   #计算法每个单词的长度   <code>wordsRDD.map(len).collect()</code>   </p>
<ul>
<li>转换操作</li>
</ul>
<p><img src="..\imgs\RDD5.jpg" alt></p>
<ul>
<li>动作操作</li>
</ul>
<p><img src="..\imgs\RDD6.jpg" alt></p>
<h2 id="键值对PairRDD："><a href="#键值对PairRDD：" class="headerlink" title="键值对PairRDD："></a>键值对PairRDD：</h2><p>是一种以（key,value)方式存储的RDD。</p>
<p>   <code>pairRDD =   wordsRDD.map(lambda x : (x , 1))</code>   </p>
<ul>
<li><p>转换操作</p>
<p><img src="..\imgs\RDD7.jpg" alt></p>
</li>
<li><p>动作操作</p>
<p><img src="..\imgs\RDD8.jpg" alt></p>
</li>
</ul>
<p>一些小问题：</p>
<p>1、spark中的RDD是什么</p>
<p>概念：<strong>分布式数据集，**</strong>spark<strong>**中基本的数据抽象，代表一个不可变、可分区、元素可并行计算的集合。</strong></p>
<p>2、RDD的五大特性：</p>
<p>①有一个<strong>分区</strong>列表，即能被切分，可并行。</p>
<p>②由一个<strong>函数</strong>计算每一个分片</p>
<p>③<strong>容错机制</strong>，对其他RDD的<strong>依赖</strong>（宽依赖和窄依赖），但并非所有RDD都要依赖。</p>
<p>RDD每次transformations（转换）都会生成一个新的RDD，两者之间会形成依赖关系。在部分分区数据丢失时，可通过依赖关系重新计算丢失的数据。</p>
<p>④key-value型的RDD是根据<strong>哈希</strong>来分区的，控制Key分到哪个reduce。</p>
<p>⑤每一分片<strong>计算优先位置</strong>，比如HDFS的block的所在位置应该是优先计算的位置。</p>
<p>3、概述一下spark中的常用算子区别（map、mapPartitions、foreach、foreachPartition）</p>
<table>
<thead>
<tr>
<th>map</th>
<th>遍历RDD，将函数f应用于每一个元素，返回新的RDD</th>
<th>transformation算子</th>
</tr>
</thead>
<tbody>
<tr>
<td>mapPartitions</td>
<td>用于遍历操作RDD中的每一个分区，返回生成一个新的RDD</td>
<td>transformation</td>
</tr>
<tr>
<td>collect</td>
<td>将RDD元素送回Master并返回List类型</td>
<td>Action</td>
</tr>
<tr>
<td>foreach</td>
<td>用于遍历RDD,将函数f应用于每一个元素，无返回值</td>
<td>action算子</td>
</tr>
<tr>
<td>foreachPartition</td>
<td>用于遍历操作RDD中的每一个分区。无返回值</td>
<td>action算子</td>
</tr>
<tr>
<td>总结</td>
<td>一般使用mapPartitions或者foreachPartition算子比map和foreach更加高效，推荐使用。</td>
</tr>
</tbody>
</table>
<p>4、谈谈spark中的宽窄依赖</p>
<ul>
<li>RDD和它依赖的父RDD的关系有两种不同的类型，即窄依赖和宽依赖。</li>
<li>宽依赖：指的是多个子RDD的Partition会依赖同一个父RDD的Partition分区【需要shuffle，与其他RDD交换资料】 例如 groupByKey、 reduceByKey、 sortByKey等操作会产生宽依赖，会产生shuffle      </li>
<li>窄依赖：指的是每一个父RDD的Partition最多被子RDD的一个Partition分区使用。【原地变换，不需要shuffle】      例如map、filter、union等操作会产生窄依赖 </li>
</ul>
<p>5、spark中如何划分stage</p>
<p>Stage划分的依据就是宽依赖，何时产生宽依赖，例如reduceByKey,groupByKey的算子，会导致宽依赖的产生。</p>
<table>
<thead>
<tr>
<th>先介绍什么是RDD中的宽窄依赖，</th>
</tr>
</thead>
<tbody>
<tr>
<td>然后在根据DAG有向无环图进行划分，从当前job的最后一个算子往前推，遇到宽依赖，那么当前在这个批次中的所有算子操作都划分成一个stage,</td>
</tr>
<tr>
<td>然后继续按照这种方式在继续往前推，如在遇到宽依赖，又划分成一个stage,一直到最前面的一个算子。</td>
</tr>
<tr>
<td>最后整个job会被划分成多个stage,而stage之间又存在依赖关系，后面的stage依赖于前面的stage。</td>
</tr>
</tbody>
</table>
<h1 id="五、代码学习"><a href="#五、代码学习" class="headerlink" title="五、代码学习"></a>五、代码学习</h1><h3 id="1-建立RDD"><a href="#1-建立RDD" class="headerlink" title="1. 建立RDD"></a>1. 建立RDD</h3><p><strong>创建RDD的两种方法：</strong></p>
<p>1 读取一个数据集(SparkContext.textFile()) : lines = sc.textFile(“README.md”)<br>2 读取一个集合(SparkContext.parallelize()) : lines = sc.paralelize(List(“pandas”,”i like pandas”))</p>
<p><img src="E:\GitHub_learn\blog\source\imgs\rdd_1.jpg" alt></p>
<p>#take操作将前若干个数据汇集到Driver，相比collect安全</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建RDD</span></span><br><span class="line"><span class="comment"># 从并行集合创建</span></span><br><span class="line">pairRDD=sc.parallelize([(<span class="string">'a'</span>,<span class="number">7</span>),(<span class="string">'a'</span>,<span class="number">2</span>),(<span class="string">'b'</span>,<span class="number">2</span>)]) <span class="comment"># key-value对RDD</span></span><br><span class="line">rdd1=sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">rdd2=sc.parallelize(range(<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#collect操作将数据汇集到Driver,数据过大时有超内存风险</span></span><br><span class="line">all_data = rdd.collect()</span><br><span class="line">all_data</span><br><span class="line"></span><br><span class="line"><span class="comment">#take操作将前若干个数据汇集到Driver，相比collect安全</span></span><br><span class="line">rdd = sc.parallelize(range(<span class="number">10</span>),<span class="number">5</span>) </span><br><span class="line">part_data = rdd.take(<span class="number">4</span>)</span><br><span class="line">part_data</span><br><span class="line"></span><br><span class="line"><span class="comment">#takeSample可以随机取若干个到Driver,第一个参数设置是否放回抽样</span></span><br><span class="line">rdd = sc.parallelize(range(<span class="number">10</span>),<span class="number">5</span>) </span><br><span class="line">sample_data = rdd.takeSample(<span class="literal">False</span>,<span class="number">10</span>,<span class="number">0</span>)</span><br><span class="line">sample_data</span><br><span class="line"></span><br><span class="line"><span class="comment">#first取第一个数据</span></span><br><span class="line">rdd = sc.parallelize(range(<span class="number">10</span>),<span class="number">5</span>) </span><br><span class="line">first_data = rdd.first()</span><br><span class="line">print(first_data)</span><br><span class="line"></span><br><span class="line"><span class="comment">#count查看RDD元素数量</span></span><br><span class="line">rdd = sc.parallelize(range(<span class="number">10</span>),<span class="number">5</span>)</span><br><span class="line">data_count = rdd.count()</span><br><span class="line">print(data_count)</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>从text中读取，read.text</strong></li>
</ul>
<p><img src="..\imgs\rdd_2.jpg" alt></p>
<ul>
<li><strong>从csv中读取:read.csv</strong></li>
</ul>
<p><img src="..\imgs\rdd_3.jpg" alt></p>
<ul>
<li><strong>从json中读取：read.json</strong></li>
</ul>
<p><img src="..\imgs\rdd_4.jpg" alt></p>
<h3 id="2-RDD与Dataframe的转换"><a href="#2-RDD与Dataframe的转换" class="headerlink" title="2. RDD与Dataframe的转换"></a>2. RDD与Dataframe的转换</h3><p><strong>（1）dataframe转换成rdd：</strong></p>
<p><strong>法一：datardd = dataDataframe.rdd</strong></p>
<p><strong>法二：datardd = sc.parallelize(_)</strong></p>
<p><strong>（2）rdd转换成dataframe：</strong></p>
<p><strong>dataDataFrame = spark.createDataFrame(datardd)</strong></p>
<p><img src="..\imgs\rdd_5.jpg" alt></p>
<p><img src="..\imgs\rdd_6.jpg" alt></p>
<p><img src="..\imgs\rdd_7.jpg" alt></p>
<h3 id="3-rdd函数"><a href="#3-rdd函数" class="headerlink" title="3. rdd函数"></a>3. rdd函数</h3><table>
<thead>
<tr>
<th style="text-align:left">mapReduce</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>rdd.map(func)</code></td>
<td style="text-align:left">将<a href="http://www.aisouwen.com/tags_38.html" target="_blank" rel="noopener">函数</a>应用于RDD中的每个元素并返回</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.mapValues(func)</code></td>
<td style="text-align:left">不改变key，只对value执行map</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.flatMap(func)</code></td>
<td style="text-align:left">先map后扁平化返回</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.flatMapValues(func)</code></td>
<td style="text-align:left">不改变key，只对value执行flatMap</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.reduce(func)</code></td>
<td style="text-align:left">合并RDD的元素返回</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.reduceByKey(func)</code></td>
<td style="text-align:left">合并每个key的value</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.foreach(func)</code></td>
<td style="text-align:left">用迭代的方法将函数应用于每个元素</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.keyBy(func)</code></td>
<td style="text-align:left">执行函数于每个元素创建key-value对RDD</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">pairRDD=sc.parallelize([(<span class="string">'a'</span>,<span class="number">7</span>),(<span class="string">'a'</span>,<span class="number">2</span>),(<span class="string">'b'</span>,<span class="number">2</span>)]) <span class="comment"># key-value对RDD</span></span><br><span class="line">rdd1=sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">rdd2=sc.parallelize(range(<span class="number">100</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1.map(<span class="keyword">lambda</span> x:x+<span class="number">1</span>).collect()</span><br><span class="line">[<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1.reduce(<span class="keyword">lambda</span> x,y : x+y)</span><br><span class="line"><span class="number">15</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1.keyBy(<span class="keyword">lambda</span> x:x%<span class="number">2</span>).collect()</span><br><span class="line">[(<span class="number">1</span>,<span class="number">1</span>),(<span class="number">0</span>,<span class="number">2</span>),(<span class="number">1</span>,<span class="number">3</span>),(<span class="number">0</span>,<span class="number">4</span>),(<span class="number">1</span>,<span class="number">5</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pairRDD.mapValues(<span class="keyword">lambda</span> x:x+<span class="number">1</span>).collect()</span><br><span class="line">[(<span class="string">'a'</span>,<span class="number">8</span>),(<span class="string">'a'</span>,<span class="number">3</span>),(<span class="string">'b'</span>,<span class="number">3</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pairRDD.reduceByKey(<span class="keyword">lambda</span> x,y : x+y).collect()</span><br><span class="line">[(<span class="string">'a'</span>,<span class="number">9</span>),(<span class="string">'b'</span>,<span class="number">2</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>names=sc.parallelize([<span class="string">'Elon Musk'</span>,<span class="string">'Bill Gates'</span>,<span class="string">'Jim Green'</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>names.map(<span class="keyword">lambda</span> x:x.split(<span class="string">' '</span>)).collect()</span><br><span class="line">[(<span class="string">'Elon'</span>,<span class="string">'Musk'</span>),(<span class="string">'Bill'</span>,<span class="string">'Gates'</span>),(<span class="string">'Jim'</span>,<span class="string">'Green'</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>names.flatMap(<span class="keyword">lambda</span> x:x.split(<span class="string">' '</span>)).collect()</span><br><span class="line">[<span class="string">'Elon'</span>,<span class="string">'Musk'</span>,<span class="string">'Bill'</span>,<span class="string">'Gates'</span>,<span class="string">'Jim'</span>,<span class="string">'Green'</span>]</span><br></pre></td></tr></table></figure>
<p><strong>（1）map操作</strong></p>
<p><img src="..\imgs\rdd_8.jpg" alt></p>
<p><strong>（2）collect操作</strong></p>
<p><img src="..\imgs\rdd_10.jpg" alt></p>
<table>
<thead>
<tr>
<th style="text-align:left">提取</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>rdd.collect()</code></td>
<td style="text-align:left">将RDD以列表形式返回</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.collectAsMap()</code></td>
<td style="text-align:left">将RDD以字典形式返回</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.take(n)</code></td>
<td style="text-align:left">提取前n个元素</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.takeSample(replace,n,seed)</code></td>
<td style="text-align:left">随机提取n个元素</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.first()</code></td>
<td style="text-align:left">提取第1名</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.top(n)</code></td>
<td style="text-align:left">提取前n名</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.keys()</code></td>
<td style="text-align:left">返回RDD的keys</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.values()</code></td>
<td style="text-align:left">返回RDD的values</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.isEmpty()</code></td>
<td style="text-align:left">检查RDD是否为空</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pairRDD=sc.parallelize([(<span class="string">'a'</span>,<span class="number">7</span>),(<span class="string">'a'</span>,<span class="number">2</span>),(<span class="string">'b'</span>,<span class="number">2</span>)]) <span class="comment"># key-value对RDD</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pairRDD.collectAsMap()</span><br><span class="line">&#123;<span class="string">'a'</span>: <span class="number">2</span>,<span class="string">'b'</span>: <span class="number">2</span>&#125;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pairRDD.keys().collect()</span><br><span class="line">[<span class="string">'a'</span>,<span class="string">'a'</span>,<span class="string">'b'</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pairRDD.values().collect()</span><br><span class="line">[<span class="number">7</span>,<span class="number">2</span>,<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">分组和聚合</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>rdd.groupBy(func)</code></td>
<td style="text-align:left">将RDD元素通过函数变换分组为key-iterable集</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.groupByKey()</code></td>
<td style="text-align:left">将key-value元素集分组为key-iterable集</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.aggregate(zeroValue,seqOp,combOp)</code></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.aggregateByKey(zeroValue,seqOp,combOp)</code></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.fold(zeroValue,func)</code></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.foldByKey(zeroValue,func)</code></td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pairRDD=sc.parallelize([(<span class="string">'a'</span>,<span class="number">7</span>),(<span class="string">'a'</span>,<span class="number">2</span>),(<span class="string">'b'</span>,<span class="number">2</span>)]) <span class="comment"># key-value对RDD</span></span><br><span class="line">rdd1=sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">rdd2=sc.parallelize(range(<span class="number">100</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1.groupBy(<span class="keyword">lambda</span> x: x % <span class="number">2</span>).mapValues(list).collect()</span><br><span class="line">[(<span class="number">0</span>,[<span class="number">2</span>,<span class="number">4</span>]),(<span class="number">1</span>,[<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>])]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pairRDD.groupByKey().mapValues(list).collect()</span><br><span class="line">[(<span class="string">'a'</span>,[<span class="number">7</span>,<span class="number">2</span>]),(<span class="string">'b'</span>,[<span class="number">2</span>])]</span><br></pre></td></tr></table></figure>
<blockquote>
<h3 id="更好的解决方案：reduceByKey-非groupBykey"><a href="#更好的解决方案：reduceByKey-非groupBykey" class="headerlink" title="更好的解决方案：reduceByKey,非groupBykey"></a>更好的解决方案：reduceByKey,非groupBykey</h3><p>reduceByKey能够直接将资料根据key值聚合，减少多余的交换（shuffle）动作。</p>
<p>避免使用groupbykey，如果数据量过大，会造成内存溢出。</p>
</blockquote>
<p><img src="..\imgs\rdd_11.jpg" alt></p>
<table>
<thead>
<tr>
<th style="text-align:left">选择数据</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>rdd.sample(replace,frac,seed)</code></td>
<td style="text-align:left">抽样</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.filter(func)</code></td>
<td style="text-align:left">筛选满足函数的元素(变换)</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.distinct()</code></td>
<td style="text-align:left">去重</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">rdd1=sc.parallelize([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">rdd2=sc.parallelize(range(<span class="number">100</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd2.sample(<span class="literal">False</span>,<span class="number">0.8</span>,seed=<span class="number">42</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1.filter(<span class="keyword">lambda</span> x:x%<span class="number">2</span>==<span class="number">0</span>).collect()</span><br><span class="line">[<span class="number">2</span>,<span class="number">4</span>]</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">排序</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>rdd.sortBy(func,ascending=True)</code></td>
<td style="text-align:left">按RDD元素变换后的值排序</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.sortByKey(ascending=True)</code></td>
<td style="text-align:left">按key排序</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left">统计</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>rdd.count()</code></td>
<td style="text-align:left">返回RDD中的元素数</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.countByKey()</code></td>
<td style="text-align:left">按key计算RDD元素数量</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.countByValue()</code></td>
<td style="text-align:left">按RDD元素计算数量</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.sum()</code></td>
<td style="text-align:left">求和</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.mean()</code></td>
<td style="text-align:left">平均值</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.max()</code></td>
<td style="text-align:left">最大值</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.min()</code></td>
<td style="text-align:left">最小值</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.stdev()</code></td>
<td style="text-align:left">标准差</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.variance()</code></td>
<td style="text-align:left">方差</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.histograme()</code></td>
<td style="text-align:left">分箱（Bin）生成直方图</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.stats()</code></td>
<td style="text-align:left">综合统计（计数、平均值、标准差、最大值和最小值）</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">pairRDD=sc.parallelize([(<span class="string">'a'</span>,<span class="number">7</span>),(<span class="string">'a'</span>,<span class="number">2</span>),(<span class="string">'b'</span>,<span class="number">2</span>)]) <span class="comment"># key-value对RDD</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pairRDD.count()</span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pairRDD.countByKey()</span><br><span class="line">defaultdict(&lt;type <span class="string">'int'</span>&gt;,&#123;<span class="string">'a'</span>:<span class="number">2</span>,<span class="string">'b'</span>:<span class="number">1</span>&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pairRDD.countByValue()</span><br><span class="line">defaultdict(&lt;type <span class="string">'int'</span>&gt;,&#123;(<span class="string">'b'</span>,<span class="number">2</span>):<span class="number">1</span>,(<span class="string">'a'</span>,<span class="number">2</span>):<span class="number">1</span>,(<span class="string">'a'</span>,<span class="number">7</span>):<span class="number">1</span>&#125;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd2.histogram(<span class="number">3</span>)</span><br><span class="line">([<span class="number">0</span>,<span class="number">33</span>,<span class="number">66</span>,<span class="number">99</span>],[<span class="number">33</span>,<span class="number">33</span>,<span class="number">34</span>])</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">连接运算</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>rdd.union(other)</code></td>
<td style="text-align:left">并集(不去重)</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.intersection(other)</code></td>
<td style="text-align:left">交集(去重)</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.subtract(other)</code></td>
<td style="text-align:left">差集(不去重)</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.cartesian(other)</code></td>
<td style="text-align:left">笛卡尔积</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.subtractByKey(other)</code></td>
<td style="text-align:left">按key差集</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.join(other)</code></td>
<td style="text-align:left">内连接</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.leftOuterJoin(other)</code></td>
<td style="text-align:left">左连接</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.rightOuterJoin(other)</code></td>
<td style="text-align:left">右连接</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1=sc.parallelize([<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd2=sc.parallelize([<span class="number">1</span>,<span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1.union(rdd1).collect()</span><br><span class="line">[<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1.intersection(rdd2).collect()</span><br><span class="line">[<span class="number">1</span>,<span class="number">3</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1.subtract(rdd2).collect()</span><br><span class="line">[<span class="number">5</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd2.cartesian(rdd2).collect()</span><br><span class="line">[(<span class="number">1</span>,<span class="number">1</span>),(<span class="number">1</span>,<span class="number">3</span>),(<span class="number">3</span>,<span class="number">1</span>),(<span class="number">3</span>,<span class="number">3</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1=sc.parallelize([(<span class="string">'a'</span>,<span class="number">7</span>),(<span class="string">'a'</span>,<span class="number">2</span>),(<span class="string">'b'</span>,<span class="number">2</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd2=sc.parallelize([(<span class="string">'b'</span>,<span class="string">'B'</span>),(<span class="string">'c'</span>,<span class="string">'C'</span>)])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1.subtractByKey(rdd2).collect()</span><br><span class="line">[(<span class="string">'a'</span>,<span class="number">7</span>),(<span class="string">'a'</span>,<span class="number">2</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rdd1.join(rdd2).collect()</span><br><span class="line">[(<span class="string">'b'</span>,(<span class="number">2</span>,<span class="string">'B'</span>))]</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th style="text-align:left">持久化</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>rdd.persist()</code></td>
<td style="text-align:left">标记为持久化</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.cache()</code></td>
<td style="text-align:left">等价于<code>rdd.persist(MEMORY_ONLY)</code></td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.unpersist()</code></td>
<td style="text-align:left">释放缓存</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left">分区</th>
<th style="text-align:left">说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>rdd.getNumPartitions()</code></td>
<td style="text-align:left">获取RDD分区数</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.repartition(n)</code></td>
<td style="text-align:left">新建一个含n个分区的RDD</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.coalesce(n)</code></td>
<td style="text-align:left">将RDD中的分区减至n个</td>
</tr>
<tr>
<td style="text-align:left"><code>rdd.partitionBy(key,func)</code></td>
<td style="text-align:left">自定义分区</td>
</tr>
</tbody>
</table>
<p><strong>文件系统读写</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取</span></span><br><span class="line">rdd=sc.textFile(<span class="string">'hdfs://file_path'</span>)  <span class="comment"># 从hdfs集群读取</span></span><br><span class="line">rdd=sc.textFile(<span class="string">'file_path'</span>) </span><br><span class="line">rdd=sc.textFile(<span class="string">'file:///local_file_path'</span>) <span class="comment"># 从本地文件读取</span></span><br><span class="line"><span class="comment"># 保存</span></span><br><span class="line">rdd.saveAsTextFile(<span class="string">'hdfs://file_path'</span>)</span><br><span class="line">rdd.saveAsTextFile(<span class="string">'file_path'</span>) <span class="comment"># hdfs路径</span></span><br><span class="line">rdd.saveAsTextFile(<span class="string">'file:///local_file_path'</span>)</span><br></pre></td></tr></table></figure>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Spark简介/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Spark简介/" itemprop="url">Spark简介</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-03-09T00:00:00+08:00">
                2023-03-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文仅做学习总结，如有侵权立删</p>
<p><a href="https://blog.csdn.net/weixin_42331985/article/details/124126019" target="_blank" rel="noopener">https://blog.csdn.net/weixin_42331985/article/details/124126019</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/396809439" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/396809439</a></p>
<p><a href="https://blog.csdn.net/czz1141979570/article/details/105877261/" target="_blank" rel="noopener">https://blog.csdn.net/czz1141979570/article/details/105877261/</a></p>
<p>[TOC]</p>
<h1 id="Spark生态架构图"><a href="#Spark生态架构图" class="headerlink" title="Spark生态架构图"></a>Spark生态架构图</h1><h1 id="Spark简介"><a href="#Spark简介" class="headerlink" title="Spark简介"></a>Spark简介</h1><h2 id="1-概念"><a href="#1-概念" class="headerlink" title="1. 概念"></a>1. 概念</h2><p><img src="..\imgs\spark组件介绍.jpg" alt></p>
<blockquote>
<p><strong>Spark：</strong>基于内存的迭代式计算引擎。</p>
<p><strong>RDD：</strong>Resillient Distributed Dataset（弹性分布式数据集），是分布式内存的一个抽象概念。</p>
<p><strong>DAG：</strong>Directed Acyclic Graph（有向无环图），反映RDD之间的依赖关系。</p>
<p><img src="https://img-blog.csdnimg.cn/99c95c8e6e724185b86fa7e0ba42f7fc.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAUmVsaWFu5ZOI5ZOI,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img"></p>
<p><strong>Executor</strong>：是运行在工作节点（WorkerNode）的一个进程，负责运行Task</p>
<p><strong>应用（Application）</strong>：用户编写的Spark应用程序</p>
<p><strong>任务（ Task ）</strong>：运行在Executor上的工作单元(线程)</p>
<p><strong>作业（ Job ）</strong>：一个作业包含多个RDD及作用于相应RDD上的各种操作</p>
<p><strong>阶段（ Stage ）</strong>：是作业的基本调度单位，一个作业会分为多组任务，每组任务被称为阶段，或者也被称为任务集合，代表了一组关联的、相互之间没有Shuffle依赖关系的任务组成的任务集, 下图为DAG划分Stage过程：</p>
<p><img src="https://img-blog.csdnimg.cn/70e593dbb2c54f53a01f239947f7e451.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAUmVsaWFu5ZOI5ZOI,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img"></p>
</blockquote>
<h2 id="2-组件关系"><a href="#2-组件关系" class="headerlink" title="2. 组件关系"></a>2. 组件关系</h2><p>当执行一个Application时，Driver会向Yarn申请资源，启动Executor（Worker），并向Executor发送代码和文件，执行任务，任务结束后执行结果会返回给任务控制节点，或者写到HDFS/Hive等。</p>
<p>1 Application = 1 Driver + 多 Job </p>
<p>1 Job（多个 RDD + RDD的操作） = 多个Stage </p>
<p>1 Stage = 多个Task</p>
<p><img src="..\imgs\Spark组件关系.jpg" alt></p>
<p><img src="..\imgs\Spark基本组件.jpg" alt></p>
<h2 id="3-运行流程"><a href="#3-运行流程" class="headerlink" title="3. 运行流程"></a>3. 运行流程</h2><h3 id="（1）概念层级"><a href="#（1）概念层级" class="headerlink" title="（1）概念层级"></a>（1）概念层级</h3><p>解释1：</p>
<blockquote>
<ol>
<li><p>一个Spark提交时，由Driver运行main方法创建一个SparkContext，由SparkContext负责和Yarn的通信、资源的申请、任务的分配和监控等。</p>
<p>SparkContext会向Yarn注册并申请运行Executor的资源。</p>
</li>
<li><p>Yarn为Executor分配资源，启动Executor进程，Executor发送心跳到Yarn上</p>
</li>
<li><p>SparkContext根据RDD的依赖关系构建DAG图，DAG调度解析后将图分解成多个Stage，并计算出之间的依赖关系，将这些Job集提交给Task调度器处理。Executor向SparkContext申请Task，Task调度器将Task分发给Executor运行，同时，SparkContext将Application代码发放给Executor。</p>
</li>
<li><p>任务在Executor上运行，结果反馈给Job调度器，再反馈给DAG调度器，运行完毕后写入数据并释放所有资源。</p>
</li>
</ol>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/1115a2d3fe534bd8b172961157a56eb2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemt5Q29kZXI=,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<p>解释2：</p>
<blockquote>
<p>每个 worker 节点包含一个或者多个 executor，一个 executor 中又包含多个 task。task 是真正实现并行计算的最小工作单元。</p>
<ul>
<li><h3 id="Driver"><a href="#Driver" class="headerlink" title="Driver"></a>Driver</h3><p>Driver 是一个 Java 进程，负责执行 Spark 任务的 main 方法，它的职责有：</p>
<ul>
<li><p>执行用户提交的代码，创建 SparkContext 或者 SparkSession</p>
</li>
<li><p>将用户代码转化为Spark任务（Jobs）</p>
</li>
<li><ul>
<li>创建血缘（Lineage），逻辑计划（Logical Plan）和物理计划（Physical Plan)</li>
</ul>
</li>
<li><p>在 Cluster Manager 的辅助下，把 task 任务分发调度出去</p>
</li>
<li><p>跟踪任务的执行情况</p>
</li>
</ul>
</li>
<li><h3 id="Spark-Context-Session"><a href="#Spark-Context-Session" class="headerlink" title="Spark Context/Session"></a>Spark Context/Session</h3><p>它是由Spark driver创建，每个 Spark 应用对应一个。程序和集群交互的入口。可以连接到 Cluster Manager</p>
</li>
<li><h3 id="Cluster-Manager"><a href="#Cluster-Manager" class="headerlink" title="Cluster Manager"></a>Cluster Manager</h3><p>负责部署整个Spark 集群，包括上面提到的 driver 和 executors。具有以下几种部署模式</p>
<ol>
<li>Standalone 模式</li>
<li>YARN</li>
<li>Mesos</li>
<li>Kubernetes</li>
</ol>
</li>
<li><h3 id="Executor"><a href="#Executor" class="headerlink" title="Executor"></a>Executor</h3><p>一个创建在 worker 节点的进程。一个 Executor 有多个 slots(线程) 可以并发执行多个 tasks。</p>
<ul>
<li>负责执行spark任务，把结果返回给 Driver</li>
<li>可以将数据缓存到 worker 节点的内存</li>
<li>一个 slot 就是一个线程，对应了一个 task</li>
</ul>
</li>
</ul>
<p><img src="..\imgs\Spark架构.jpg" alt></p>
</blockquote>
<p><img src="..\imgs\Spark代码执行流程.jpg" alt></p>
<h3 id="（2）代码层级"><a href="#（2）代码层级" class="headerlink" title="（2）代码层级"></a>（2）代码层级</h3><p>Spark 有懒加载的特性，也就是说 Spark 计算按兵不动，直到遇到 action 类型的 operator 的时候才会触发一次计算。</p>
<blockquote>
<ul>
<li><p>DAG</p>
<ul>
<li>Spark Job如何执行，都是由这个 DAG 来管的，包括决定 task 运行在什么节点</li>
</ul>
</li>
<li><p>Spark Job</p>
<ul>
<li>每个Spark Job 对应一个action</li>
</ul>
</li>
<li><p>Stages</p>
<ul>
<li>每个 Spark Job 包含一系列 stages</li>
<li>Stages 按照数据是否需要 shuffle 来划分（宽依赖）</li>
<li>Stages 之间的执行是串行的（除非stage 间计算的RDD不同）</li>
<li>因为 Stages 是串行的，所以 shuffle 越少越好</li>
</ul>
</li>
<li><p>Tasks</p>
<ul>
<li>每个 stage 包含一系列的 tasks</li>
<li>Tasks 是并行计算的最小单元</li>
<li>一个 stage 中的所有 tasks 执行同一段代码逻辑，只是基于不同的数据块</li>
<li>一个 task 只能在一个executor中执行，不能是多个</li>
<li>一个 stage 输出的 partition 数量等于这个 stage 执行 tasks 的数量</li>
</ul>
</li>
<li><p>Partition</p>
<ul>
<li>Spark 中 partition（分区） 可以理解为内存中的一个数据集</li>
<li>一个 partition 对应一个 task，一个 task 对应 一个 executor 中的一个 slot，一个 slot 对应物理资源是一个线程 thread</li>
<li>1 partition = 1 task = 1 slot = 1 thread</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="3-spark中Master与Worker区别及Driver与Executor区别"><a href="#3-spark中Master与Worker区别及Driver与Executor区别" class="headerlink" title="(3) spark中Master与Worker区别及Driver与Executor区别"></a>(3) spark中Master与Worker区别及Driver与Executor区别</h3><p><img src="..\imgs\Master和Worker关系.jpg" alt></p>
<p><img src="..\imgs\Driver和Executor关系.jpg" alt></p>
<p> Master和Worker是Spark的守护进程，即Spark在特定模式下正常运行所必须的进程。Driver和Executor是临时程序，当有具体任务提交到Spark集群才会开启的程序。</p>
<p><a href="https://blog.csdn.net/nicole_33/article/details/122520395" target="_blank" rel="noopener">了解 Spark中的master、worker和Driver、Executor</a></p>
<h2 id="4-DAGScheduler具体流程"><a href="#4-DAGScheduler具体流程" class="headerlink" title="4. DAGScheduler具体流程"></a>4. DAGScheduler具体流程</h2><p>DAG负责的是将RDD中的数据依赖划分为不同可以并行的宽依赖task， 这些不同的task集合统称为stage，最后将这些stage推送给TaskScheduler进行调度，DAG的具体划分过程如下所示：</p>
<p><img src="..\imgs\DAG流程.jpg" alt></p>
<blockquote>
<ul>
<li><code>窄依赖经历的是map、filter等操作没有进行相关的shuffle，而宽依赖则通常都是join等操作需要进行一定的shuffle意味着需要打散均匀等操作</code></li>
<li>1 stage是触发action的时候 <strong>从后往前划分</strong> 的，所以本图要从RDD_G开始划分。</li>
<li>2 RDD_G依赖于RDD_B和RDD_F，随机决定先判断哪一个依赖，但是对于结果无影响。</li>
<li>3 RDD_B与RDD_G属于窄依赖，所以他们属于同一个stage，RDD_B与老爹RDD_A之间是宽依赖的关系，所以他们不能划分在一起，所以RDD_A自己是一个stage1</li>
<li>4 RDD_F与RDD_G是属于宽依赖，他们不能划分在一起，所以最后一个stage的范围也就限定了，RDD_B和RDD_G组成了Stage3</li>
<li>5 RDD_F与两个爹RDD_D、RDD_E之间是窄依赖关系，RDD_D与爹RDD_C之间也是窄依赖关系，所以他们都属于同一个stage2</li>
<li>6 执行过程中stage1和stage2相互之间没有前后关系所以可以并行执行，相应的每个stage内部各个partition对应的task也并行执行</li>
<li>7 stage3依赖stage1和stage2执行结果的partition，只有等前两个stage执行结束后才可以启动stage3.</li>
<li>8 我们前面有介绍过Spark的Task有两种：ShuffleMapTask和ResultTask，其中后者在DAG最后一个阶段推送给Executor，其余所有阶段推送的都是ShuffleMapTask。在这个案例中stage1和stage2中产生的都是ShuffleMapTask，在stage3中产生的ResultTask。</li>
<li>9 虽然stage的划分是从后往前计算划分的，但是依赖逻辑判断等结束后真正创建stage是从前往后的。也就是说如果从stage的ID作为标识的话，先需要执行的stage的ID要小于后需要执行的ID。就本案例来说，stage1和stage2的ID要小于stage3，至于stage1和stage2的ID谁大谁小是随机的，是由前面第2步决定的。</li>
</ul>
</blockquote>
<h2 id="5-MR和spark区别"><a href="#5-MR和spark区别" class="headerlink" title="5. MR和spark区别"></a>5. MR和spark区别</h2><blockquote>
<h3 id="（1）中间结果输出："><a href="#（1）中间结果输出：" class="headerlink" title="（1）中间结果输出："></a>（1）中间结果输出：</h3><ul>
<li><p>MapReduce：读–处理–写磁盘–读–处理–写磁盘（<strong>中间结果落地，即存入磁盘</strong>）</p>
</li>
<li><p>spark：读–处理–处理–（需要的时候）写磁盘（<strong>中间结果存入内存</strong>）</p>
</li>
</ul>
<p><strong>减少落地时间，速度快</strong></p>
<p><img src="../imgs/Hadoop%E5%92%8Cspark%E5%8C%BA%E5%88%AB.jpg" alt></p>
<h3 id="（2）数据格式："><a href="#（2）数据格式：" class="headerlink" title="（2）数据格式："></a>（2）数据格式：</h3><ul>
<li><p>MapReduce<strong>：从</strong>DB中读取数据再处理</p>
</li>
<li><p>spark：采用弹性分布式数据结构RDD存储数据</p>
</li>
</ul>
<h3 id="（3）容错性："><a href="#（3）容错性：" class="headerlink" title="（3）容错性："></a>（3）容错性：</h3><ul>
<li>Spark：采用RDD存储数据，若数据集丢失，可重建。</li>
</ul>
<h3 id="（4）通用性："><a href="#（4）通用性：" class="headerlink" title="（4）通用性："></a>（4）通用性：</h3><ul>
<li><p>MapReduce：只提供map和reduce两种操作。</p>
</li>
<li><p>spark：提供很多数据集操作类型（transformations、actions）【transformations包括map\filter\</p>
</li>
</ul>
<p>Groupbykey\sort等，action包括reduce、save、collect、lookup等】</p>
<h3 id="（5）执行策略"><a href="#（5）执行策略" class="headerlink" title="（5）执行策略"></a>（5）执行策略</h3><ul>
<li><p>MapReduce：数据shuffle前需排序</p>
</li>
<li><p>spark：不是所有场景都要排序</p>
</li>
</ul>
</blockquote>
<h2 id="6、spark1-x和spark2-x的区别"><a href="#6、spark1-x和spark2-x的区别" class="headerlink" title="6、spark1.x和spark2.x的区别"></a>6、spark1.x和spark2.x的区别</h2><blockquote>
<ul>
<li><p>Spark1.x：采用SparkContext作为进入点</p>
</li>
<li><p>Spark2.x：SparkSession 是 Spark SQL 的入口。</p>
<ul>
<li>采用SparkSession作为进入点，SparkSession可直接读取各种资料源，可直接与Hive元数据沟通，同时包含设定以及资源管理功能。</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="7-spark-应用执行模式"><a href="#7-spark-应用执行模式" class="headerlink" title="7. spark 应用执行模式"></a>7. spark 应用执行模式</h2><h3 id="（1）local模式"><a href="#（1）local模式" class="headerlink" title="（1）local模式"></a>（1）local模式</h3><p>local 模式主要是用于本地代码测试操作</p>
<p>本质上就是一个单进程程序, 在一个进程中运行多个线程</p>
<p>类似于pandas , 都是一个单进程程序, 无法处理大规模数据, 只需要处理小规模数据</p>
<p><img src="..\imgs\Spark环境1.jpg" alt></p>
<h3 id="（2）standalone："><a href="#（2）standalone：" class="headerlink" title="（2）standalone："></a>（2）standalone：</h3><blockquote>
<p> Spark Standalone模式：该模式是不借助于第三方资源管理框架的完全分布式模式。Spark 使用自己的 Master 进程对应用程序运行过程中所需的资源进行调度和管理；对于中小规模的 Spark 集群首选 Standalone 模式。目前Spark 在 Standalone 模式下主要是借助 Zookeeper 实现单点故障问题；思想也是类似于 Hbase Master 单点故障解决方案。</p>
</blockquote>
<h3 id="（3）YARN"><a href="#（3）YARN" class="headerlink" title="（3）YARN"></a>（3）YARN</h3><blockquote>
<p>该模式是借助于第三方资源管理框架 Yarn 的完全分布式模式。Spark 作为一个提交程序的客户端将 Job 任务提交到 Yarn 上；然后通过 Yarn 来调度和管理 Job 任务执行过程中所需的资源。需要此模式需要先搭建 Yarn 集群，然后将 Spark 作为 Hadoop 中的一个组件纳入到 Yarn 的调度管理下，这样将更有利于系统资源的共享。</p>
</blockquote>
<h2 id="8-提交任务方法"><a href="#8-提交任务方法" class="headerlink" title="8. 提交任务方法"></a>8. 提交任务方法</h2><blockquote>
<p><strong>（1）spark shell</strong></p>
<ul>
<li>spark-shell 是 Spark 自带的交互式 Shell 程序，方便用户进行交互式编程，用户可以在该命令行下用 <a href="https://so.csdn.net/so/search?q=Scala&amp;spm=1001.2101.3001.7020" target="_blank" rel="noopener">Scala</a> 编写 spark 程序。</li>
<li><p>应用场景</p>
<ul>
<li>通常是以测试为主</li>
<li>所以一般直接以<code>./spark-shell</code>启动，进入本地模式测试</li>
</ul>
</li>
<li>local方式启动：./spark-shell</li>
<li>standalone集群模式启动：./spark-shell –master spark://master:7077</li>
<li>yarn client模式启动：./spark-shell –master yarn-client</li>
</ul>
<p><strong>（2）spark submit</strong></p>
<p>使用spark 自带的spark-submit工具提交任务</p>
<p>程序一旦打包好，就可以使用 bin/spark-submit 脚本启动应用了。这个脚本负责设置 spark 使用的 classpath 和依赖，支持不同类型的集群管理器和发布模式。</p>
<p><strong>它主要是用于提交编译并打包好的Jar包到集群环境中来运行</strong>，和hadoop中的hadoop jar命令很类似，hadoop jar是提交一个MR-task,而spark-submit是提交一个spark任务，这个脚本 可以设置Spark类路径（classpath）和应用程序依赖包，并且可以设置不同的Spark所支持的集群管理和部署模式。 相对于spark-shell来讲它不具有REPL(交互式的编程环境)的，在运行前需要指定应用的启动类，jar包路径,参数等内容。</p>
</blockquote>
<h2 id="9-参数配置："><a href="#9-参数配置：" class="headerlink" title="9. 参数配置："></a>9. 参数配置：</h2><p>参数名    参数说明</p>
<ul>
<li>-class    应用程序的主类，仅针对 java 或 scala 应用</li>
<li>-master    master 的地址，提交任务到哪里执行，例如 local,spark://host:port, yarn, local</li>
<li>-deploy-mode    在本地 (client) 启动 driver 或在 cluster 上启动，默认是 client</li>
<li>-name    应用程序的名称，会显示在Spark的网页用户界面</li>
<li>-jars    用逗号分隔的本地 jar 包，设置后，这些 jar 将包含在 driver 和 executor 的 classpath 下</li>
<li>-packages    包含在driver 和executor 的 classpath 中的 jar 的 maven 坐标</li>
<li>-exclude-packages    为了避免冲突 而指定不包含的 package</li>
<li>-repositories    远程 repository</li>
<li>-conf PROP=VALUE    指定 spark 配置属性的值，例如 -conf spark.executor.extraJavaOptions=”-XX:MaxPermSize=256m”</li>
<li>-properties-file    加载的配置文件，默认为 conf/spark-defaults.conf</li>
<li>-driver-memory    Driver内存，默认 1G</li>
<li>-driver-java-options    传给 driver 的额外的 Java 选项</li>
<li>-driver-library-path    传给 driver 的额外的库路径</li>
<li>-driver-class-path    传给 driver 的额外的类路径</li>
<li>-driver-cores    Driver 的核数，默认是1。在 yarn 或者 standalone 下使用</li>
<li>-executor-memory    每个 executor 的内存，默认是1G</li>
<li>-total-executor-cores    所有 executor 总共的核数。仅仅在 mesos 或者 standalone 下使用</li>
<li>-num-executors    启动的 executor 数量。默认为2。在 yarn 下使用</li>
<li>-executor-core    每个 executor 的核数。在yarn或者standalone下使用</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/标准化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/标准化/" itemprop="url">标准化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-26T00:00:00+08:00">
                2023-02-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/标准化/" itemprop="url" rel="index">
                    <span itemprop="name">标准化</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<h2 id="一、BN批标准化"><a href="#一、BN批标准化" class="headerlink" title="一、BN批标准化"></a>一、BN批标准化</h2><h3 id="1、BN的基本动机"><a href="#1、BN的基本动机" class="headerlink" title="1、BN的基本动机"></a>1、BN的基本动机</h3><ol>
<li><strong>（初始数据分布一致）</strong>神经网络训练过程的本质是学习数据分布，如果训练数据与测试数据的分布      不同将大大降低网络的泛化能力，因此我们需要在训练开始前对所有输入数据进行归一化处理。</li>
<li><strong>（中间数据分布一致）</strong>然而随着网络训练的进行，每个隐层的参数变化使得后一层的输入发生变      化，从而每一批训练数据的分布也随之改变，致使网络在每次迭代中都需要拟合 不同的数据分布，增大训练的复杂度以及过拟合的风险。</li>
</ol>
<p>原因在于神经网络学习过程<strong>本质上是为了学习数据的分布</strong>，一旦训练数据与测试数据的分布不同，那么网络的泛化能力也大大降低；另一方面，一旦在mini-batch梯度下降训练的时候，每批训练数据的分布不相同，那么网络就要在每次迭代的时候去学习以适应不同的分布，这样将会大大降低网络的训练速度，这也正是为什么我们需要对所有训练数据做一个Normalization预处理的原因。</p>
<h3 id="2、-BN的原理"><a href="#2、-BN的原理" class="headerlink" title="2、 BN的原理"></a>2、 BN的原理</h3><p>BN首先是把所有的样本的统计分布标准化，降低了batch内不同样本的差异性，然后又允许batch内的各个样本有各自的统计分布。</p>
<p>BN是针对每一批数据，在网络的每一层输入之前增加归一化处理（均值为0，标准差为1），将所有批数据强制在统一的数据分布下，即对该层 的任意一个神经元（假设为第k维）x^(k) 采用如下公式:</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/过拟合欠拟合/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/过拟合欠拟合/" itemprop="url">过拟合</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-26T00:00:00+08:00">
                2023-02-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/过拟合/" itemprop="url" rel="index">
                    <span itemprop="name">过拟合</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<h1 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h1><h1 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a>一、概念</h1><blockquote>
<p>过拟合：模型对于训练数拟合呈过当的情况，反映到评估指标上，就是模型在训练集上表现很好，测试集和新数据上表现较差。</p>
<p>欠拟合：模型在训练和和预测时表现都不好的情况。</p>
</blockquote>
<p><img src="..\imgs\过拟合欠拟合.jpg" alt></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/概率论1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/概率论1/" itemprop="url">概率论</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-26T00:00:00+08:00">
                2023-02-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/先导知识/" itemprop="url" rel="index">
                    <span itemprop="name">先导知识</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/先导知识/概率论基本知识/" itemprop="url" rel="index">
                    <span itemprop="name">概率论基本知识</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<h1 id="一、均值、方差、协方差"><a href="#一、均值、方差、协方差" class="headerlink" title="一、均值、方差、协方差"></a>一、均值、方差、协方差</h1><ul>
<li>期望/均值：实验中每次可能结果的概率乘其结果的总和。<ul>
<li>E(X)=∑xP(X), x表示随机变量的取值，P(X)表示随机变量X=x的概率。</li>
</ul>
</li>
<li>方差：概率分布的数据期望，反映了随机变量取值的变异程度。<ul>
<li>D(x ) = E{[X-E(X)]^2} =E(X^2) - [ E(X)]^2</li>
</ul>
</li>
</ul>
<p><img src="..\imgs\协方差.jpg" alt></p>
<ul>
<li>协方差：度量两个随机变量关系的统计量<ul>
<li><img src="..\imgs\协方差2.jpg" alt></li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/正则化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/正则化/" itemprop="url">正则化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-26T00:00:00+08:00">
                2023-02-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/正则化/" itemprop="url" rel="index">
                    <span itemprop="name">正则化</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<h1 id="正则化-惩罚项"><a href="#正则化-惩罚项" class="headerlink" title="正则化/惩罚项"></a>正则化/惩罚项</h1><h2 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a>一、概念</h2><blockquote>
<p> <strong>（1）范数：</strong><img src="..\imgs\范数.jpg" alt></p>
<p><strong>（2）方差和偏差：</strong></p>
<p>Error = Bias + Variance</p>
<ul>
<li>Error反映的是整个模型的准确度，</li>
<li>Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，</li>
<li>Variance反映的是模型每一次输出结果与模型输出期望之间的误差（描述的是样本上训练的模型在测试集上的表现。），即模型的稳定性。</li>
<li>欠拟合是高bias，过拟合是高variance。</li>
</ul>
</blockquote>
<blockquote>
<p><strong>（3）正则化的目的</strong>：减少模型参数大小或者参数数量，缓解过拟合。</p>
<p>正则化的作用是给模型加一个先验，lasso(l1)认为模型是拉普拉斯分布，ridge(l2)认为是高斯分布，正则项对应参数的协方差，协方差越小，这个模型的variance越小，泛化 能力越强，也就抵抗了过拟合。</p>
<p><strong>（4）正则化通用形式：</strong></p>
<p>​        Loss_with_regularization = loss(w,x) + λf(w)</p>
<ul>
<li>正则化恒为非负</li>
<li>f(w)不能为负数，若其为负数，Loss(w,x)+λf(x)本来尽可能想让其变小，那f(x)为负数，f(x)绝对值会越学越大。</li>
</ul>
<p><strong>(5) 正则化方法：</strong>L1正则、L2正则、Dropout正则</p>
</blockquote>
<h2 id="二、-从数学角度解释正则化为什么能提升模型的泛化能力；【奥卡姆剃刀：简单就好】"><a href="#二、-从数学角度解释正则化为什么能提升模型的泛化能力；【奥卡姆剃刀：简单就好】" class="headerlink" title="二、 从数学角度解释正则化为什么能提升模型的泛化能力；【奥卡姆剃刀：简单就好】"></a>二、 从数学角度解释正则化为什么能提升模型的泛化能力；【奥卡姆剃刀：简单就好】</h2><p><strong>过拟合就是模型在学习训练样本时将噪声异常值也学习得非常好，使得模型参数过多，模型较复杂，给参数加上一个先验约束，可降低过拟合。</strong></p>
<p> <img src="..\imgs\正则化1.jpg" alt></p>
<h2 id="三、L1和L2范数各有什么特点以及相应的原因？L1和L2的区别与应用场景；"><a href="#三、L1和L2范数各有什么特点以及相应的原因？L1和L2的区别与应用场景；" class="headerlink" title="三、L1和L2范数各有什么特点以及相应的原因？L1和L2的区别与应用场景；"></a>三、L1和L2范数各有什么特点以及相应的原因？L1和L2的区别与应用场景；</h2><p><strong>区别</strong>：L1假设参数服从拉普拉斯分布，L2则符合高斯分布；</p>
<p>L1范数更容易产生稀疏的权重，L2范数更容易产生分散的权重。</p>
<p><strong>原因</strong>：（L1稀疏的原因，L2不稀疏的原因）【几何、公式两个角度】</p>
<p><strong>场景</strong>：具有高维的数据特征时采用L1正则效果好一点。因为L1具有稀疏性。</p>
<h2 id="四、解释L1范数更容易产生稀疏的权重，L2不的原因："><a href="#四、解释L1范数更容易产生稀疏的权重，L2不的原因：" class="headerlink" title="四、解释L1范数更容易产生稀疏的权重，L2不的原因："></a>四、解释L1范数更容易产生稀疏的权重，L2不的原因：</h2><h3 id="（1）几何角度"><a href="#（1）几何角度" class="headerlink" title="（1）几何角度"></a>（1）几何角度</h3><p>L2正则项约束后的解空间是圆形，L1正则项约束后的解空间是多方形，L1易在角点发生交点，从而产生稀疏解。</p>
<blockquote>
<p>绿色等高线代表未施加正则化的代价函数，菱形和圆形分别代表L1和L2正则化约束，L1-ball 与L2-ball的不同就在于L1在和每个坐标轴相交的地方都有“角”出现，而目标函数的”等高线”除非位置摆得非常好，大部分时候都会在角的地方相交。注意到在角的位置就会产生稀疏性。相比之下，L2-ball 就没有这样的性质，因为没有角，所以第一次相交的地方出现在具有稀疏性的位置的概率就变得非常小</p>
</blockquote>
<p><img src="..\imgs\L1正则解释.jpg" alt></p>
<h3 id="（2）公式角度：（拉格朗日求导）"><a href="#（2）公式角度：（拉格朗日求导）" class="headerlink" title="（2）公式角度：（拉格朗日求导）"></a>（2）公式角度：（拉格朗日求导）</h3><blockquote>
<p>深度学习花书7.1节（202页左右）。带L1正则化的最优参数w=sign(w<em>) max{|w</em>|- a/H , 0}，其中w代表未正则化的目标函数的最优参数，H代表海森矩阵，a是正则化系数，只要a足够大，w就会在更大区间范围内使w变为0，而带L2正则化的最优参数w=H/(H+a)▪w,只要w不为0，w也不为0.</p>
</blockquote>
<p><strong>1、稀疏性的约束：</strong></p>
<p><img src="..\imgs\正则公式1.jpg" alt></p>
<p>​    L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。</p>
<p><strong>2、不好求解，松弛为L1，L2：</strong></p>
<p><img src="..\imgs\正则公式2.jpg" alt></p>
<p><strong>3、拉格朗日</strong></p>
<p><img src="..\imgs\正则公式3.jpg" alt></p>
<h3 id="（3）贝叶斯先验"><a href="#（3）贝叶斯先验" class="headerlink" title="（3）贝叶斯先验"></a>（3）贝叶斯先验</h3><blockquote>
<p>L1正则化相当于对模型参数w引入了拉普拉斯先验，L2正则化相当于引入了高斯先验，而拉普拉斯先验使参数为0的可能性更大。</p>
</blockquote>
<p><strong>L1正则化可通过假设权重w的先验分布为拉普拉斯分布，由最大后验概率估计导出。</strong></p>
<p><strong>L2正则化可通过假设权重w的先验分布为高斯分布，由最大后验概率估计导出。</strong></p>
<p><strong>详细解释：</strong> <a href="https://blog.csdn.net/m0_38045485/article/details/82147817" target="_blank" rel="noopener">https://blog.csdn.net/m0_38045485/article/details/82147817</a></p>
<p><img src="..\imgs\正则公式4.jpg" alt></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/广告校准/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/广告校准/" itemprop="url">广告校准</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-25T00:00:00+08:00">
                2023-02-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/计算广告/" itemprop="url" rel="index">
                    <span itemprop="name">计算广告</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/计算广告/校准广告/" itemprop="url" rel="index">
                    <span itemprop="name">校准广告</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<p><a href="https://zhuanlan.zhihu.com/p/460061332" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/460061332</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/582530785" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/582530785</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/398235467" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/398235467</a></p>
<h1 id="广告校准"><a href="#广告校准" class="headerlink" title="广告校准"></a>广告校准</h1><h2 id="1-业务背景"><a href="#1-业务背景" class="headerlink" title="1. 业务背景"></a>1. 业务背景</h2><blockquote>
<p>广告三大角色：广告主、媒体、DSP</p>
<ol>
<li>ctr : (Click Through Rate) 点击率 = click / show， 曝光广告中用户点击的概率。</li>
<li>cvr: (Conversion Rate) 转化率 = order / click，点击广告中用户转化的概率。（如注册，激活，创角等）</li>
<li>cpa：(Cost per Action) 转化成本 = cost / order, 表示广告主每获得一个转化需付的成本。</li>
<li>ecpm / rpm：= ctr <em> cvr </em> cpa<ol>
<li>ecpm : 对广告主来说，(Effective Cost Per Mile) 每千次展示的有效费用。 </li>
<li>rpm：对DSP来说，(Revenue Per Mile)每千次展示的收入。</li>
</ol>
</li>
<li>pctr: (Predict CTR) 预估点击率</li>
<li>pcvr: (Predict CVR) 预估转化率</li>
</ol>
</blockquote>
<h2 id="2-面临的问题"><a href="#2-面临的问题" class="headerlink" title="2. 面临的问题"></a>2. 面临的问题</h2><blockquote>
<p>（1）模型准确性存在偏差，受限于</p>
<p>​    实际分布和离线分布的差异</p>
<p>​    模型学习能力</p>
<p>（2）预估模型的准确性度量</p>
<p>​    <strong>AUC：</strong>仅作为排序指标，无法度量预估值的大小准确性</p>
<p>​    <strong>COPC：</strong>（Click On Predict Click) = sum( 实际ctr) / sum(pctr)</p>
<p>​            用于评估某段细分的流量模型预估值是否偏差较大。</p>
<p>（3）校准评价指标：</p>
<p>​    <strong>PCOC：</strong>（predict click over click）COPC是相反的指标。</p>
<p>​    <strong>cal-N：（calibration-N）</strong></p>
<p>​        cal-N将样本集合分桶后分别计算PCOC，并计算与1的偏差作为标准误差。举个例子，将pctr根据值大小划分为多个桶，每个桶为一个簇，计算每个簇的PCOC及其与1的偏差 数学公式:</p>
<p><img src="..\imgs\校准评价指标.jpg" alt></p>
<p>​    <strong>GC-N：（grouped calibration-N）</strong></p>
<p>​        在具体业务场景下，有时会重点关注某一维度下的校准效果(如广告计费维度)，GC-N可以解决这个问题，它可以在cal-N基础上自定义各维度权重。例如，下面这个式子定义了m个广告计划的GC-N 数学公式:</p>
</blockquote>
<h2 id="3-校准算法"><a href="#3-校准算法" class="headerlink" title="3. 校准算法"></a>3. 校准算法</h2><p><img src="https://pic2.zhimg.com/80/v2-c452e8c2822418e0b744fe751123b275_720w.webp" alt="img"></p>
<h3 id="（1）-Bias-Correction：负采样率修正"><a href="#（1）-Bias-Correction：负采样率修正" class="headerlink" title="（1） Bias Correction：负采样率修正"></a>（1） Bias Correction：负采样率修正</h3><blockquote>
<p><strong>原因：</strong>正负样本不均衡情况下，负采样通常可以提升模型的AUC精度，但pctr值会发生变化，与真实差距扩大。</p>
<p><strong>校准公式：</strong></p>
<p><img src="..\imgs\采样校准1.jpg" alt></p>
<p>因此可以计算出校准后的bias: <strong>b′=b+log(n)</strong></p>
</blockquote>
<p><strong>代码：</strong></p>
<p>注意在导出模型时，最终结果过完sigmoid，再进行bias_correct。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_correct</span><span class="params">(b, nr)</span>:</span></span><br><span class="line">	<span class="string">"""</span></span><br><span class="line"><span class="string">	nr: neg_sample_rate</span></span><br><span class="line"><span class="string">	</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">    <span class="keyword">if</span> nr &lt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> b + math.log(nr)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> b</span><br><span class="line"></span><br><span class="line">nr = <span class="number">0.1</span> <span class="comment"># 负采样率</span></span><br><span class="line">last_op[<span class="string">'bias'</span>] = bias_correct(last_op[<span class="string">'bias'</span>]， nr) <span class="comment"># 纠正sigmoid后的bias</span></span><br></pre></td></tr></table></figure>
<h3 id="（2）校准算法—保序回归"><a href="#（2）校准算法—保序回归" class="headerlink" title="（2）校准算法—保序回归"></a>（2）校准算法—保序回归</h3><blockquote>
<p>解决模型高低估、模型over-confidence等问题。</p>
</blockquote>
<p><img src="..\imgs\保序回归.jpg" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_sir_calibration_model</span><span class="params">(pctr_list = [<span class="number">0.01</span>,<span class="number">0.02</span>,<span class="number">0.03</span>,<span class="number">0.04</span>], ctr_list = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>], bin_size = <span class="number">0.01</span>)</span>:</span></span><br><span class="line">	sort_ctr_list = sorted(list(zip(pctr_list, ctr_list)), key = <span class="keyword">lambda</span> x:x[<span class="number">0</span>])</span><br><span class="line">    bin_index = <span class="number">0</span></span><br><span class="line">    ind = <span class="number">0</span></span><br><span class="line">    n = len(ctr_list)</span><br><span class="line">    cctr_res = []</span><br><span class="line">    <span class="keyword">while</span> ind &lt; n:</span><br><span class="line">        <span class="keyword">while</span> (bin_index + bin_size) &lt; sort_ctr_list[ind][<span class="number">0</span>]:</span><br><span class="line">            cctr_res.append(sort_ctr_list[ind][<span class="number">1</span>])</span><br><span class="line">            bin_index += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> (bin_index + bin_size) == sort_ctr_list[ind][<span class="number">0</span>]:</span><br><span class="line">            cctr_res.append(sort_ctr_list[ind][<span class="number">1</span>])</span><br><span class="line">            ind += <span class="number">1</span></span><br><span class="line">            bin_index += bin_size</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> ind + <span class="number">1</span>== n:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        tmp_cctr = sort_ctr_list[ind + <span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">        tmp_num = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> ind + <span class="number">1</span> &lt; n <span class="keyword">and</span> bin_index + bin_size &gt; sort_ctr_list[ind][<span class="number">0</span>]:</span><br><span class="line">            tmp_cctr += sort_ctr_list[ind][<span class="number">1</span>]</span><br><span class="line">            tmp_num += <span class="number">1</span></span><br><span class="line">            ind += <span class="number">1</span></span><br><span class="line">        cctr_res.append(tmp_cctr/tmp_num)</span><br><span class="line">        bin_index += bin_size</span><br></pre></td></tr></table></figure>
<h3 id="（3）校准算法3-—-SIR（保序回归平滑校准算法）"><a href="#（3）校准算法3-—-SIR（保序回归平滑校准算法）" class="headerlink" title="（3）校准算法3 —-SIR（保序回归平滑校准算法）"></a>（3）校准算法3 —-SIR（保序回归平滑校准算法）</h3><blockquote>
<p>解决桶间数据稀疏问题</p>
</blockquote>
<p><img src="..\imgs\保序回归平滑校准1.jpg" alt></p>
<blockquote>
<p> SIR算法是18年提出的，如上图所示，结合了Binning、Isotonic Regression和线性Scaling方法。</p>
</blockquote>
<p>具体思想为：</p>
<ol>
<li><p>进行保序回归。</p>
</li>
<li><p>使用单调平滑函数拟合模型预估值和实际点击率的映射关系（线性Scaling）就得到了校准函数。</p>
</li>
</ol>
<p>该算法的优势在于充分利用了<strong>保序和平滑</strong>思想缓解了<strong>数据稀疏</strong>的问题。</p>
<p>（详细可见论文：﻿Calibrating user response predictions in online advertising）。</p>
<h3 id="（4）校准算法4—贝叶斯平滑SIR校准算法（Bayes-SIR"><a href="#（4）校准算法4—贝叶斯平滑SIR校准算法（Bayes-SIR" class="headerlink" title="（4）校准算法4—贝叶斯平滑SIR校准算法（Bayes-SIR)"></a>（4）校准算法4—贝叶斯平滑SIR校准算法（Bayes-SIR)</h3><blockquote>
<ul>
<li><p>Bayes-SIR解决冷启动问题。</p>
</li>
<li><p>beta分布：可以看作一个概率的概率分布</p>
<p><a href="https://blog.csdn.net/a358463121/article/details/52562940" target="_blank" rel="noopener">带你理解beta分布</a></p>
</li>
<li><p>贝叶斯平滑方法:（最早在雅虎的一篇论文里面中提出，用于解决数据稀疏问题下的点击率预估优化）。</p>
</li>
</ul>
</blockquote>
<p>在SIR算法应用中，发现广告计划投放初期校准效果明显差于平均水平，并在实际业务中造成以下问题：</p>
<p>1）影响新建计划初始阶段的投放表现；</p>
<p>2）影响强时效性广告的全生命周期效果；</p>
<p>3）小客户在整个投放周期里数据一直稀疏，得不到准确的校准，影响竞价公平性。</p>
<p>这是SIR校准算法的冷启动问题，采用了Bayes平滑的思想进行优化.</p>
<p><a href><img src="..\imgs\贝叶斯SIR.jpg" alt></a></p>
<p>Bayes-SIR的算法思想：如上图所示，</p>
<ol>
<li><p>从丰富的先验数据中估计出每个广告计划的点击率先验分布，</p>
</li>
<li><p>依据该先验知识求解出belta分布的参数α和β。</p>
</li>
<li>依据α和β和新观测到的少量数据，计算得到更准确的后验点击率。</li>
</ol>
<p>这种估计方法能充分利用先验知识，具备置信程度过渡平滑的特点。</p>
<p>将贝叶斯平滑CTR估计过程替换掉SIR算法的朴素CTR统计逻辑即构成了具有冷启动问题优化效果的校准方法。</p>
<p>实际上线后，新广告的投放效果得到明显的提升。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/向量乘积/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/向量乘积/" itemprop="url">向量乘积</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-21T00:00:00+08:00">
                2023-02-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/先导知识/" itemprop="url" rel="index">
                    <span itemprop="name">先导知识</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/先导知识/向量乘积/" itemprop="url" rel="index">
                    <span itemprop="name">向量乘积</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<h1 id="向量乘积"><a href="#向量乘积" class="headerlink" title="向量乘积"></a>向量乘积</h1><h2 id="1-内积"><a href="#1-内积" class="headerlink" title="1. 内积"></a>1. 内积</h2><blockquote>
<p> 含义：两个向量的相似度/向量的夹角， 标量。</p>
</blockquote>
<p>向量a和向量b的余弦的相似度: 对内积进行了归一化</p>
<p>​    cosθ = 内积 / (|a| * |b| )</p>
<h2 id="2-哈达玛积"><a href="#2-哈达玛积" class="headerlink" title="2. 哈达玛积"></a>2. 哈达玛积</h2><blockquote>
<p>元素两两相乘。</p>
</blockquote>
<p>[a1, b1, c1] * [a2, b2, c2] = [a1a2, b1b2, c1c2]</p>
<p><strong>元素集的交互：</strong> [w1<em> a1a2, w2 </em> b1b2, w3 *c1c2]</p>
<p><strong>向量级别的交互：</strong>w [a1a2, b1b2, c1c2]</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/梯度下降/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/梯度下降/" itemprop="url">梯度下降</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-21T00:00:00+08:00">
                2023-02-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/梯度下降/" itemprop="url" rel="index">
                    <span itemprop="name">梯度下降</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<p>[TOC]</p>
<h1 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h1><h2 id="1-重点"><a href="#1-重点" class="headerlink" title="1. 重点"></a>1. 重点</h2><blockquote>
<p>(1) 常用的优化方法：牛顿法、GD、拟牛顿法、共轭梯度法，之间的区别</p>
<p>(2) GD三种变形：BGD、SGD、MBGD</p>
<p>(3) 多种改进方法：Momentum、NAG、Adagrad、Adadelta、RMSProp、Adam</p>
</blockquote>
<h2 id="2-概念"><a href="#2-概念" class="headerlink" title="2. 概念"></a>2. 概念</h2><h3 id="（1）常用的优化方法：直接法、迭代法（梯度下降、牛顿法、拟牛顿法、共轭梯度法）"><a href="#（1）常用的优化方法：直接法、迭代法（梯度下降、牛顿法、拟牛顿法、共轭梯度法）" class="headerlink" title="（1）常用的优化方法：直接法、迭代法（梯度下降、牛顿法、拟牛顿法、共轭梯度法）"></a>（1）常用的优化方法：直接法、迭代法（梯度下降、牛顿法、拟牛顿法、共轭梯度法）</h3><h3 id="（2）直接法（求解析解）："><a href="#（2）直接法（求解析解）：" class="headerlink" title="（2）直接法（求解析解）："></a>（2）直接法（求解析解）：</h3><p>求梯度，令梯度为0</p>
<h3 id="（3）牛顿法："><a href="#（3）牛顿法：" class="headerlink" title="（3）牛顿法："></a>（3）牛顿法：</h3><p><img src="..\imgs\牛顿法.jpg" alt></p>
<p><img src="..\imgs\牛顿法2.jpg" alt></p>
<h3 id="（4）-GD-梯度下降"><a href="#（4）-GD-梯度下降" class="headerlink" title="（4） GD 梯度下降:"></a>（4） GD 梯度下降:</h3><p>让变量沿着目标函数负梯度的方向移动，直到移动到极小值点。</p>
<p>从拉格朗日中值定理 / 泰勒展开一阶公式都可以推出损失函数下降最大的方向是梯度方向。</p>
<p><img src="..\imgs\梯度下降方法解释.jpg" alt></p>
<p><img src="..\imgs\梯度下降方法1.jpg" alt></p>
<h2 id="3-梯度下降法和牛顿法的区别"><a href="#3-梯度下降法和牛顿法的区别" class="headerlink" title="3. 梯度下降法和牛顿法的区别"></a>3. 梯度下降法和牛顿法的区别</h2><p><strong>牛顿法和梯度下降法对比：</strong></p>
<ul>
<li><strong>从公式上看</strong>，牛顿法是二阶收敛，梯度下降是一阶收敛（局部最优），所以牛顿法就更快。</li>
</ul>
<p>【如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。】</p>
<ul>
<li><strong>从几何上看</strong>，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。</li>
</ul>
<h2 id="4-三种变形"><a href="#4-三种变形" class="headerlink" title="4. 三种变形"></a>4. 三种变形</h2><p>GD的三种变形：BGD、SGD、MBGD</p>
<p>这三种形式的区别就是取决于我们用多少数据来计算目标函数的梯度。</p>
<h3 id="（1）Batch-gradient-descend【批量梯度下降】"><a href="#（1）Batch-gradient-descend【批量梯度下降】" class="headerlink" title="（1）Batch gradient descend【批量梯度下降】"></a>（1）Batch gradient descend【批量梯度下降】</h3><ul>
<li><p>定义：【采用整个训练数据集的数据计算损失函数对参数的梯度】<br><img src="..\imgs\BGD.jpg" alt></p>
</li>
<li><p>优点：全局最优解；易于并行实现；</p>
</li>
<li>缺点：大样本数据计算速度非常慢，不能投入新数据实时更新模型。</li>
<li>收敛：对于凸函数可以收敛到全局最优，对于非凸函数可以收敛到局部最优。</li>
</ul>
<h3 id="（2）-Stochastic-gradient-descent【随机梯度下降】【适合在线更新】"><a href="#（2）-Stochastic-gradient-descent【随机梯度下降】【适合在线更新】" class="headerlink" title="（2） Stochastic gradient descent【随机梯度下降】【适合在线更新】"></a>（2） Stochastic gradient descent【随机梯度下降】【适合在线更新】</h3><ul>
<li>定义：SGD  每次更新时对一个样本进行梯度更新。<br> <img src="..\imgs\SGD.jpg" alt></li>
<li>优点：对于很大的数据集来说，可能会有相似的样本，这样 BGD在计算梯度时会出现冗余， 而 SGD 一次只进行一次更新，就没有冗余，而且比较快，并且可以新增样本。</li>
<li>缺点：但是 SGD 因为更新比较频繁，会造成 cost  function 有严重的震荡。准确度下降，不易于并行实现。<br> <img src="..\imgs\SGD缺点.jpg" alt></li>
<li>收敛性：不一定每次更新朝着最优值方向，因为存在噪音点，局部最优。</li>
</ul>
<h3 id="（3）mini-batch-GD【小批量梯度下降】：降低随机梯度的方差"><a href="#（3）mini-batch-GD【小批量梯度下降】：降低随机梯度的方差" class="headerlink" title="（3）mini-batch GD【小批量梯度下降】：降低随机梯度的方差"></a>（3）mini-batch GD【小批量梯度下降】：降低随机梯度的方差</h3><p>【在更新每一参数时都使用一部分样本来进行更新】</p>
<p><img src="..\imgs\MBGD&#39;.jpg" alt>‘</p>
<ul>
<li>缺点：需要指定batch大小，收敛性不好。</li>
<li>一般batch取2的幂次能充分利用矩阵运算操作（32,64,128……）</li>
<li><img src="..\imgs\MBGD.jpg" alt></li>
</ul>
<p><strong>三种方法的使用情况：</strong></p>
<p>如果样本量比较小，采用批量梯度下降算法。如果样本太大，或者在线算法，使用随机梯度下降算法。在实际的一般情况下，采用小批量梯度下降算法。</p>
<p><strong>GD具有的几个问题：</strong></p>
<p>1、学习率选择【太小，收敛速度慢，太大，在最优值附近震荡】</p>
<p>2、学习率不固定【稀疏数据，学习率可增大】</p>
<p>3、（尤其SGD）对于非凸函数，易陷于局部最优值/鞍点。</p>
<h2 id="5、优化方法"><a href="#5、优化方法" class="headerlink" title="5、优化方法"></a>5、优化方法</h2><h3 id="（1）动量Momentum【一般为SGD-momentum】"><a href="#（1）动量Momentum【一般为SGD-momentum】" class="headerlink" title="（1）动量Momentum【一般为SGD+momentum】"></a>（1）动量Momentum【一般为SGD+momentum】</h3><blockquote>
<p><strong>原理：</strong>因为SGD易陷于局部最优点或鞍点，一种帮助SGD在相关方向进行加速并抑制振荡的方法</p>
</blockquote>
<p><img src="..\imgs\Momentum_SGD.jpg" alt></p>
<p><img src="..\imgs\Momentum_SGD_1.jpg" alt></p>
<p>momentum表示要在多大程度上保留原来的更新方向，这个值在0-1之间<strong>，在训练开始时，由于梯度可能会很大，所以初始值一般选为0.5；当梯度不那么大时</strong>，一般改为0.9。<br>α是学习率，即当前batch的梯度多大程度上影响最终更新方向，跟普通的SGD含义相同。</p>
<ul>
<li>优点：因此获得了更快的收敛性和减少了震荡。</li>
<li>缺点：这种情况相当于小球从山上滚下来时是在盲目地沿着坡滚，如果它能具备一些先知，例如快要上坡时，就知道需要减速了的话，适应性会更好。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Lee_yl</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lee_yl</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
