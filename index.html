<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Lee_yl&#39;s blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Lee_yl&#39;s blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Lee_yl&#39;s blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>Lee_yl's blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Lee_yl's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/理解RDD/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/理解RDD/" itemprop="url">RDD</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-03-10T00:00:00+08:00">
                2023-03-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/spark/" itemprop="url" rel="index">
                    <span itemprop="name">spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文仅做学习总结，如有侵权立删</p>
<h1 id="一、理解RDD"><a href="#一、理解RDD" class="headerlink" title="一、理解RDD"></a>一、理解RDD</h1><blockquote>
<p> RDD可以被抽象地理解为一个大的数组，但是这个数组是分布在集群上的。</p>
<p><img src="..\imgs\RDD的理解.jpg" alt></p>
</blockquote>
<h1 id="二、RDD的生命周期"><a href="#二、RDD的生命周期" class="headerlink" title="二、RDD的生命周期"></a>二、RDD的生命周期</h1><p>创建—变换—动作（结束）</p>
<h1 id="三、RDD依赖"><a href="#三、RDD依赖" class="headerlink" title="三、RDD依赖"></a>三、RDD依赖</h1><p>1、窄依赖（RDD）—–原地变换，不需要shuffle【即各个RDD之间不需要统计】</p>
<p><img src="..\imgs\RDD1.jpg" alt></p>
<p>2、宽依赖（RDD）—–需要shuffle，与其他RDD交换资料，时间消耗长。</p>
<p><img src="..\imgs\RDD2.jpg" alt></p>
<p>3、任务优化，如</p>
<p><img src="..\imgs\RDD3.jpg" alt></p>
<h1 id="四、RDD的基本操作"><a href="#四、RDD的基本操作" class="headerlink" title="四、RDD的基本操作"></a>四、RDD的基本操作</h1><p>RDD可以有两种计算操作算子：Transformation（变换）与Action（行动）。</p>
<p><img src="..\imgs\RDD4.jpg" alt></p>
<h2 id="1、基本的RDD"><a href="#1、基本的RDD" class="headerlink" title="1、基本的RDD"></a>1、基本的RDD</h2><p>（1）建立RDD</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wordsList =  [<span class="string">'cat'</span>,<span class="string">'ele'</span>,<span class="string">'rat'</span>,<span class="string">'rat'</span>,<span class="string">'cat'</span>]</span><br><span class="line">wordsRDD =  sc.parallelize(wordsList , <span class="number">4</span>)</span><br></pre></td></tr></table></figure>
<p>   #建立RDD   <code>wordsList =   [&#39;cat&#39;,&#39;ele&#39;,&#39;rat&#39;,&#39;rat&#39;,&#39;cat&#39;]</code>   <code>wordsRDD =   sc.parallelize(wordsList , 4)</code>   </p>
<p>   #计算法每个单词的长度   <code>wordsRDD.map(len).collect()</code>   </p>
<ul>
<li>转换操作</li>
</ul>
<p><img src="..\imgs\RDD5.jpg" alt></p>
<ul>
<li>动作操作</li>
</ul>
<p><img src="..\imgs\RDD6.jpg" alt></p>
<h2 id="键值对PairRDD："><a href="#键值对PairRDD：" class="headerlink" title="键值对PairRDD："></a>键值对PairRDD：</h2><p>是一种以（key,value)方式存储的RDD。</p>
<p>   <code>pairRDD =   wordsRDD.map(lambda x : (x , 1))</code>   </p>
<ul>
<li><p>转换操作</p>
<p><img src="..\imgs\RDD7.jpg" alt></p>
</li>
<li><p>动作操作</p>
<p><img src="..\imgs\RDD8.jpg" alt></p>
</li>
</ul>
<p>一些小问题：</p>
<p>1、spark中的RDD是什么</p>
<p>概念：<strong>分布式数据集，**</strong>spark<strong>**中基本的数据抽象，代表一个不可变、可分区、元素可并行计算的集合。</strong></p>
<p>2、RDD的五大特性：</p>
<p>①有一个<strong>分区</strong>列表，即能被切分，可并行。</p>
<p>②由一个<strong>函数</strong>计算每一个分片</p>
<p>③<strong>容错机制</strong>，对其他RDD的<strong>依赖</strong>（宽依赖和窄依赖），但并非所有RDD都要依赖。</p>
<p>RDD每次transformations（转换）都会生成一个新的RDD，两者之间会形成依赖关系。在部分分区数据丢失时，可通过依赖关系重新计算丢失的数据。</p>
<p>④key-value型的RDD是根据<strong>哈希</strong>来分区的，控制Key分到哪个reduce。</p>
<p>⑤每一分片<strong>计算优先位置</strong>，比如HDFS的block的所在位置应该是优先计算的位置。</p>
<p>3、概述一下spark中的常用算子区别（map、mapPartitions、foreach、foreachPartition）</p>
<table>
<thead>
<tr>
<th>map</th>
<th>遍历RDD，将函数f应用于每一个元素，返回新的RDD</th>
<th>transformation算子</th>
</tr>
</thead>
<tbody>
<tr>
<td>mapPartitions</td>
<td>用于遍历操作RDD中的每一个分区，返回生成一个新的RDD</td>
<td>transformation</td>
</tr>
<tr>
<td>collect</td>
<td>将RDD元素送回Master并返回List类型</td>
<td>Action</td>
</tr>
<tr>
<td>foreach</td>
<td>用于遍历RDD,将函数f应用于每一个元素，无返回值</td>
<td>action算子</td>
</tr>
<tr>
<td>foreachPartition</td>
<td>用于遍历操作RDD中的每一个分区。无返回值</td>
<td>action算子</td>
</tr>
<tr>
<td>总结</td>
<td>一般使用mapPartitions或者foreachPartition算子比map和foreach更加高效，推荐使用。</td>
</tr>
</tbody>
</table>
<p>4、谈谈spark中的宽窄依赖</p>
<ul>
<li>RDD和它依赖的父RDD的关系有两种不同的类型，即窄依赖和宽依赖。</li>
<li>宽依赖：指的是多个子RDD的Partition会依赖同一个父RDD的Partition分区【需要shuffle，与其他RDD交换资料】 例如 groupByKey、 reduceByKey、 sortByKey等操作会产生宽依赖，会产生shuffle      </li>
<li>窄依赖：指的是每一个父RDD的Partition最多被子RDD的一个Partition分区使用。【原地变换，不需要shuffle】      例如map、filter、union等操作会产生窄依赖 </li>
</ul>
<p>5、spark中如何划分stage</p>
<p>Stage划分的依据就是宽依赖，何时产生宽依赖，例如reduceByKey,groupByKey的算子，会导致宽依赖的产生。</p>
<table>
<thead>
<tr>
<th>先介绍什么是RDD中的宽窄依赖，</th>
</tr>
</thead>
<tbody>
<tr>
<td>然后在根据DAG有向无环图进行划分，从当前job的最后一个算子往前推，遇到宽依赖，那么当前在这个批次中的所有算子操作都划分成一个stage,</td>
</tr>
<tr>
<td>然后继续按照这种方式在继续往前推，如在遇到宽依赖，又划分成一个stage,一直到最前面的一个算子。</td>
</tr>
<tr>
<td>最后整个job会被划分成多个stage,而stage之间又存在依赖关系，后面的stage依赖于前面的stage。</td>
</tr>
</tbody>
</table>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/Spark简介/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/Spark简介/" itemprop="url">Spark简介</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-03-09T00:00:00+08:00">
                2023-03-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本文仅做学习总结，如有侵权立删</p>
<p><a href="https://blog.csdn.net/weixin_42331985/article/details/124126019" target="_blank" rel="noopener">https://blog.csdn.net/weixin_42331985/article/details/124126019</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/396809439" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/396809439</a></p>
<p><a href="https://blog.csdn.net/czz1141979570/article/details/105877261/" target="_blank" rel="noopener">https://blog.csdn.net/czz1141979570/article/details/105877261/</a></p>
<p>[TOC]</p>
<h1 id="Spark简介"><a href="#Spark简介" class="headerlink" title="Spark简介"></a>Spark简介</h1><h2 id="1-概念"><a href="#1-概念" class="headerlink" title="1. 概念"></a>1. 概念</h2><p><img src="..\imgs\spark组件介绍.jpg" alt></p>
<blockquote>
<p><strong>Spark：</strong>基于内存的迭代式计算引擎。</p>
<p><strong>RDD：</strong>Resillient Distributed Dataset（弹性分布式数据集），是分布式内存的一个抽象概念。</p>
<p><strong>DAG：</strong>Directed Acyclic Graph（有向无环图），反映RDD之间的依赖关系。</p>
<p><img src="https://img-blog.csdnimg.cn/99c95c8e6e724185b86fa7e0ba42f7fc.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAUmVsaWFu5ZOI5ZOI,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img"></p>
<p><strong>Executor</strong>：是运行在工作节点（WorkerNode）的一个进程，负责运行Task</p>
<p><strong>应用（Application）</strong>：用户编写的Spark应用程序</p>
<p><strong>任务（ Task ）</strong>：运行在Executor上的工作单元(线程)</p>
<p><strong>作业（ Job ）</strong>：一个作业包含多个RDD及作用于相应RDD上的各种操作</p>
<p><strong>阶段（ Stage ）</strong>：是作业的基本调度单位，一个作业会分为多组任务，每组任务被称为阶段，或者也被称为任务集合，代表了一组关联的、相互之间没有Shuffle依赖关系的任务组成的任务集, 下图为DAG划分Stage过程：</p>
<p><img src="https://img-blog.csdnimg.cn/70e593dbb2c54f53a01f239947f7e451.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAUmVsaWFu5ZOI5ZOI,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img"></p>
</blockquote>
<h2 id="2-组件关系"><a href="#2-组件关系" class="headerlink" title="2. 组件关系"></a>2. 组件关系</h2><p>当执行一个Application时，Driver会向Yarn申请资源，启动Executor（Worker），并向Executor发送代码和文件，执行任务，任务结束后执行结果会返回给任务控制节点，或者写到HDFS/Hive等。</p>
<p>1 Application = 1 Driver + 多 Job </p>
<p>1 Job（多个 RDD + RDD的操作） = 多个Stage </p>
<p>1 Stage = 多个Task</p>
<p><img src="..\imgs\Spark组件关系.jpg" alt></p>
<p><img src="..\imgs\Spark基本组件.jpg" alt></p>
<h2 id="3-运行流程"><a href="#3-运行流程" class="headerlink" title="3. 运行流程"></a>3. 运行流程</h2><h3 id="（1）概念层级"><a href="#（1）概念层级" class="headerlink" title="（1）概念层级"></a>（1）概念层级</h3><p>解释1：</p>
<blockquote>
<ol>
<li><p>一个Spark提交时，由Driver运行main方法创建一个SparkContext，由SparkContext负责和Yarn的通信、资源的申请、任务的分配和监控等。</p>
<p>SparkContext会向Yarn注册并申请运行Executor的资源。</p>
</li>
<li><p>Yarn为Executor分配资源，启动Executor进程，Executor发送心跳到Yarn上</p>
</li>
<li><p>SparkContext根据RDD的依赖关系构建DAG图，DAG调度解析后将图分解成多个Stage，并计算出之间的依赖关系，将这些Job集提交给Task调度器处理。Executor向SparkContext申请Task，Task调度器将Task分发给Executor运行，同时，SparkContext将Application代码发放给Executor。</p>
</li>
<li><p>任务在Executor上运行，结果反馈给Job调度器，再反馈给DAG调度器，运行完毕后写入数据并释放所有资源。</p>
</li>
</ol>
</blockquote>
<p><img src="https://img-blog.csdnimg.cn/1115a2d3fe534bd8b172961157a56eb2.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAemt5Q29kZXI=,size_19,color_FFFFFF,t_70,g_se,x_16" alt="在这里插入图片描述"></p>
<p>解释2：</p>
<blockquote>
<p>每个 worker 节点包含一个或者多个 executor，一个 executor 中又包含多个 task。task 是真正实现并行计算的最小工作单元。</p>
<ul>
<li><h3 id="Driver"><a href="#Driver" class="headerlink" title="Driver"></a>Driver</h3><p>Driver 是一个 Java 进程，负责执行 Spark 任务的 main 方法，它的职责有：</p>
<ul>
<li><p>执行用户提交的代码，创建 SparkContext 或者 SparkSession</p>
</li>
<li><p>将用户代码转化为Spark任务（Jobs）</p>
</li>
<li><ul>
<li>创建血缘（Lineage），逻辑计划（Logical Plan）和物理计划（Physical Plan)</li>
</ul>
</li>
<li><p>在 Cluster Manager 的辅助下，把 task 任务分发调度出去</p>
</li>
<li><p>跟踪任务的执行情况</p>
</li>
</ul>
</li>
<li><h3 id="Spark-Context-Session"><a href="#Spark-Context-Session" class="headerlink" title="Spark Context/Session"></a>Spark Context/Session</h3><p>它是由Spark driver创建，每个 Spark 应用对应一个。程序和集群交互的入口。可以连接到 Cluster Manager</p>
</li>
<li><h3 id="Cluster-Manager"><a href="#Cluster-Manager" class="headerlink" title="Cluster Manager"></a>Cluster Manager</h3><p>负责部署整个Spark 集群，包括上面提到的 driver 和 executors。具有以下几种部署模式</p>
<ol>
<li>Standalone 模式</li>
<li>YARN</li>
<li>Mesos</li>
<li>Kubernetes</li>
</ol>
</li>
<li><h3 id="Executor"><a href="#Executor" class="headerlink" title="Executor"></a>Executor</h3><p>一个创建在 worker 节点的进程。一个 Executor 有多个 slots(线程) 可以并发执行多个 tasks。</p>
<ul>
<li>负责执行spark任务，把结果返回给 Driver</li>
<li>可以将数据缓存到 worker 节点的内存</li>
<li>一个 slot 就是一个线程，对应了一个 task</li>
</ul>
</li>
</ul>
<p><img src="..\imgs\Spark架构.jpg" alt></p>
</blockquote>
<p><img src="..\imgs\Spark代码执行流程.jpg" alt></p>
<h3 id="（2）代码层级"><a href="#（2）代码层级" class="headerlink" title="（2）代码层级"></a>（2）代码层级</h3><p>Spark 有懒加载的特性，也就是说 Spark 计算按兵不动，直到遇到 action 类型的 operator 的时候才会触发一次计算。</p>
<blockquote>
<ul>
<li><p>DAG</p>
<ul>
<li>Spark Job如何执行，都是由这个 DAG 来管的，包括决定 task 运行在什么节点</li>
</ul>
</li>
<li><p>Spark Job</p>
<ul>
<li>每个Spark Job 对应一个action</li>
</ul>
</li>
<li><p>Stages</p>
<ul>
<li>每个 Spark Job 包含一系列 stages</li>
<li>Stages 按照数据是否需要 shuffle 来划分（宽依赖）</li>
<li>Stages 之间的执行是串行的（除非stage 间计算的RDD不同）</li>
<li>因为 Stages 是串行的，所以 shuffle 越少越好</li>
</ul>
</li>
<li><p>Tasks</p>
<ul>
<li>每个 stage 包含一系列的 tasks</li>
<li>Tasks 是并行计算的最小单元</li>
<li>一个 stage 中的所有 tasks 执行同一段代码逻辑，只是基于不同的数据块</li>
<li>一个 task 只能在一个executor中执行，不能是多个</li>
<li>一个 stage 输出的 partition 数量等于这个 stage 执行 tasks 的数量</li>
</ul>
</li>
<li><p>Partition</p>
<ul>
<li>Spark 中 partition（分区） 可以理解为内存中的一个数据集</li>
<li>一个 partition 对应一个 task，一个 task 对应 一个 executor 中的一个 slot，一个 slot 对应物理资源是一个线程 thread</li>
<li>1 partition = 1 task = 1 slot = 1 thread</li>
</ul>
</li>
</ul>
</blockquote>
<h3 id="3-spark中Master与Worker区别及Driver与Executor区别"><a href="#3-spark中Master与Worker区别及Driver与Executor区别" class="headerlink" title="(3) spark中Master与Worker区别及Driver与Executor区别"></a>(3) spark中Master与Worker区别及Driver与Executor区别</h3><p><img src="..\imgs\Master和Worker关系.jpg" alt></p>
<p><img src="..\imgs\Driver和Executor关系.jpg" alt></p>
<p> Master和Worker是Spark的守护进程，即Spark在特定模式下正常运行所必须的进程。Driver和Executor是临时程序，当有具体任务提交到Spark集群才会开启的程序。</p>
<p><a href="https://blog.csdn.net/nicole_33/article/details/122520395" target="_blank" rel="noopener">了解 Spark中的master、worker和Driver、Executor</a></p>
<h2 id="4-spark特点"><a href="#4-spark特点" class="headerlink" title="4. spark特点"></a>4. spark特点</h2><blockquote>
<ol>
<li>运行速度快 <ol>
<li>提供了RDD数据结构，可在内存计算，采用DAG进行计算操作，中间结果保存在内存中。MR是基于磁盘的。</li>
<li>spark是基于线程运行的，MR是基于进程的，线程的启动和销毁要高于进程</li>
</ol>
</li>
<li>易用性<ol>
<li>多语言</li>
<li>更高阶的API</li>
</ol>
</li>
<li>通用性强<ol>
<li>spark core</li>
<li>spark SQL</li>
<li>spark streaming</li>
<li>spark MLlib</li>
<li>spark grapgX</li>
</ol>
</li>
</ol>
</blockquote>
<p><img src="..\imgs\Spark_module.jpg" alt></p>
<h2 id="5-MR和spark区别"><a href="#5-MR和spark区别" class="headerlink" title="5. MR和spark区别"></a>5. MR和spark区别</h2><blockquote>
<h3 id="（1）中间结果输出："><a href="#（1）中间结果输出：" class="headerlink" title="（1）中间结果输出："></a>（1）中间结果输出：</h3><ul>
<li><p>MapReduce：读–处理–写磁盘–读–处理–写磁盘（<strong>中间结果落地，即存入磁盘</strong>）</p>
</li>
<li><p>spark：读–处理–处理–（需要的时候）写磁盘（<strong>中间结果存入内存</strong>）</p>
</li>
</ul>
<p><strong>减少落地时间，速度快</strong></p>
<p><img src="../imgs/Hadoop%E5%92%8Cspark%E5%8C%BA%E5%88%AB.jpg" alt></p>
<h3 id="（2）数据格式："><a href="#（2）数据格式：" class="headerlink" title="（2）数据格式："></a>（2）数据格式：</h3><ul>
<li><p>MapReduce<strong>：从</strong>DB中读取数据再处理</p>
</li>
<li><p>spark：采用弹性分布式数据结构RDD存储数据</p>
</li>
</ul>
<h3 id="（3）容错性："><a href="#（3）容错性：" class="headerlink" title="（3）容错性："></a>（3）容错性：</h3><ul>
<li>Spark：采用RDD存储数据，若数据集丢失，可重建。</li>
</ul>
<h3 id="（4）通用性："><a href="#（4）通用性：" class="headerlink" title="（4）通用性："></a>（4）通用性：</h3><ul>
<li><p>MapReduce：只提供map和reduce两种操作。</p>
</li>
<li><p>spark：提供很多数据集操作类型（transformations、actions）【transformations包括map\filter\</p>
</li>
</ul>
<p>Groupbykey\sort等，action包括reduce、save、collect、lookup等】</p>
<h3 id="（5）执行策略"><a href="#（5）执行策略" class="headerlink" title="（5）执行策略"></a>（5）执行策略</h3><ul>
<li><p>MapReduce：数据shuffle前需排序</p>
</li>
<li><p>spark：不是所有场景都要排序</p>
</li>
</ul>
</blockquote>
<h2 id="6、spark1-x和spark2-x的区别"><a href="#6、spark1-x和spark2-x的区别" class="headerlink" title="6、spark1.x和spark2.x的区别"></a>6、spark1.x和spark2.x的区别</h2><blockquote>
<ul>
<li><p>Spark1.x：采用SparkContext作为进入点</p>
</li>
<li><p>Spark2.x：SparkSession 是 Spark SQL 的入口。</p>
<ul>
<li>采用SparkSession作为进入点，SparkSession可直接读取各种资料源，可直接与Hive元数据沟通，同时包含设定以及资源管理功能。</li>
</ul>
</li>
</ul>
</blockquote>
<h2 id="7-spark-应用执行模式"><a href="#7-spark-应用执行模式" class="headerlink" title="7. spark 应用执行模式"></a>7. spark 应用执行模式</h2><h3 id="（1）local模式"><a href="#（1）local模式" class="headerlink" title="（1）local模式"></a>（1）local模式</h3><p>local 模式主要是用于本地代码测试操作</p>
<p>本质上就是一个单进程程序, 在一个进程中运行多个线程</p>
<p>类似于pandas , 都是一个单进程程序, 无法处理大规模数据, 只需要处理小规模数据</p>
<p><img src="..\imgs\Spark环境1.jpg" alt></p>
<h3 id="（2）standalone："><a href="#（2）standalone：" class="headerlink" title="（2）standalone："></a>（2）standalone：</h3><blockquote>
<p> Spark Standalone模式：该模式是不借助于第三方资源管理框架的完全分布式模式。Spark 使用自己的 Master 进程对应用程序运行过程中所需的资源进行调度和管理；对于中小规模的 Spark 集群首选 Standalone 模式。目前Spark 在 Standalone 模式下主要是借助 Zookeeper 实现单点故障问题；思想也是类似于 Hbase Master 单点故障解决方案。</p>
</blockquote>
<h3 id="（3）YARN"><a href="#（3）YARN" class="headerlink" title="（3）YARN"></a>（3）YARN</h3><blockquote>
<p>该模式是借助于第三方资源管理框架 Yarn 的完全分布式模式。Spark 作为一个提交程序的客户端将 Job 任务提交到 Yarn 上；然后通过 Yarn 来调度和管理 Job 任务执行过程中所需的资源。需要此模式需要先搭建 Yarn 集群，然后将 Spark 作为 Hadoop 中的一个组件纳入到 Yarn 的调度管理下，这样将更有利于系统资源的共享。</p>
</blockquote>
<h2 id="8-提交任务方法"><a href="#8-提交任务方法" class="headerlink" title="8. 提交任务方法"></a>8. 提交任务方法</h2><blockquote>
<p><strong>（1）spark shell</strong></p>
<ul>
<li>spark-shell 是 Spark 自带的交互式 Shell 程序，方便用户进行交互式编程，用户可以在该命令行下用 <a href="https://so.csdn.net/so/search?q=Scala&amp;spm=1001.2101.3001.7020" target="_blank" rel="noopener">Scala</a> 编写 spark 程序。</li>
<li><p>应用场景</p>
<ul>
<li>通常是以测试为主</li>
<li>所以一般直接以<code>./spark-shell</code>启动，进入本地模式测试</li>
</ul>
</li>
<li>local方式启动：./spark-shell</li>
<li>standalone集群模式启动：./spark-shell –master spark://master:7077</li>
<li>yarn client模式启动：./spark-shell –master yarn-client</li>
</ul>
<p><strong>（2）spark submit</strong></p>
<p>使用spark 自带的spark-submit工具提交任务</p>
<p>程序一旦打包好，就可以使用 bin/spark-submit 脚本启动应用了。这个脚本负责设置 spark 使用的 classpath 和依赖，支持不同类型的集群管理器和发布模式。</p>
<p><strong>它主要是用于提交编译并打包好的Jar包到集群环境中来运行</strong>，和hadoop中的hadoop jar命令很类似，hadoop jar是提交一个MR-task,而spark-submit是提交一个spark任务，这个脚本 可以设置Spark类路径（classpath）和应用程序依赖包，并且可以设置不同的Spark所支持的集群管理和部署模式。 相对于spark-shell来讲它不具有REPL(交互式的编程环境)的，在运行前需要指定应用的启动类，jar包路径,参数等内容。</p>
</blockquote>
<h2 id="9-参数配置："><a href="#9-参数配置：" class="headerlink" title="9. 参数配置："></a>9. 参数配置：</h2><p>参数名    参数说明</p>
<ul>
<li>-class    应用程序的主类，仅针对 java 或 scala 应用</li>
<li>-master    master 的地址，提交任务到哪里执行，例如 local,spark://host:port, yarn, local</li>
<li>-deploy-mode    在本地 (client) 启动 driver 或在 cluster 上启动，默认是 client</li>
<li>-name    应用程序的名称，会显示在Spark的网页用户界面</li>
<li>-jars    用逗号分隔的本地 jar 包，设置后，这些 jar 将包含在 driver 和 executor 的 classpath 下</li>
<li>-packages    包含在driver 和executor 的 classpath 中的 jar 的 maven 坐标</li>
<li>-exclude-packages    为了避免冲突 而指定不包含的 package</li>
<li>-repositories    远程 repository</li>
<li>-conf PROP=VALUE    指定 spark 配置属性的值，例如 -conf spark.executor.extraJavaOptions=”-XX:MaxPermSize=256m”</li>
<li>-properties-file    加载的配置文件，默认为 conf/spark-defaults.conf</li>
<li>-driver-memory    Driver内存，默认 1G</li>
<li>-driver-java-options    传给 driver 的额外的 Java 选项</li>
<li>-driver-library-path    传给 driver 的额外的库路径</li>
<li>-driver-class-path    传给 driver 的额外的类路径</li>
<li>-driver-cores    Driver 的核数，默认是1。在 yarn 或者 standalone 下使用</li>
<li>-executor-memory    每个 executor 的内存，默认是1G</li>
<li>-total-executor-cores    所有 executor 总共的核数。仅仅在 mesos 或者 standalone 下使用</li>
<li>-num-executors    启动的 executor 数量。默认为2。在 yarn 下使用</li>
<li>-executor-core    每个 executor 的核数。在yarn或者standalone下使用</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/正则化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/正则化/" itemprop="url">正则化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-26T00:00:00+08:00">
                2023-02-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/正则化/" itemprop="url" rel="index">
                    <span itemprop="name">正则化</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<h1 id="正则化-惩罚项"><a href="#正则化-惩罚项" class="headerlink" title="正则化/惩罚项"></a>正则化/惩罚项</h1><h2 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a>一、概念</h2><blockquote>
<p> <strong>（1）范数：</strong><img src="..\imgs\范数.jpg" alt></p>
<p><strong>（2）方差和偏差：</strong></p>
<p>Error = Bias + Variance</p>
<ul>
<li>Error反映的是整个模型的准确度，</li>
<li>Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，</li>
<li>Variance反映的是模型每一次输出结果与模型输出期望之间的误差（描述的是样本上训练的模型在测试集上的表现。），即模型的稳定性。</li>
<li>欠拟合是高bias，过拟合是高variance。</li>
</ul>
</blockquote>
<blockquote>
<p><strong>（3）正则化的目的</strong>：减少模型参数大小或者参数数量，缓解过拟合。</p>
<p>正则化的作用是给模型加一个先验，lasso(l1)认为模型是拉普拉斯分布，ridge(l2)认为是高斯分布，正则项对应参数的协方差，协方差越小，这个模型的variance越小，泛化 能力越强，也就抵抗了过拟合。</p>
<p><strong>（4）正则化通用形式：</strong></p>
<p>​        Loss_with_regularization = loss(w,x) + λf(w)</p>
<ul>
<li>正则化恒为非负</li>
<li>f(w)不能为负数，若其为负数，Loss(w,x)+λf(x)本来尽可能想让其变小，那f(x)为负数，f(x)绝对值会越学越大。</li>
</ul>
<p><strong>(5) 正则化方法：</strong>L1正则、L2正则、Dropout正则</p>
</blockquote>
<h2 id="二、-从数学角度解释正则化为什么能提升模型的泛化能力；【奥卡姆剃刀：简单就好】"><a href="#二、-从数学角度解释正则化为什么能提升模型的泛化能力；【奥卡姆剃刀：简单就好】" class="headerlink" title="二、 从数学角度解释正则化为什么能提升模型的泛化能力；【奥卡姆剃刀：简单就好】"></a>二、 从数学角度解释正则化为什么能提升模型的泛化能力；【奥卡姆剃刀：简单就好】</h2><p><strong>过拟合就是模型在学习训练样本时将噪声异常值也学习得非常好，使得模型参数过多，模型较复杂，给参数加上一个先验约束，可降低过拟合。</strong></p>
<p> <img src="..\imgs\正则化1.jpg" alt></p>
<h2 id="三、L1和L2范数各有什么特点以及相应的原因？L1和L2的区别与应用场景；"><a href="#三、L1和L2范数各有什么特点以及相应的原因？L1和L2的区别与应用场景；" class="headerlink" title="三、L1和L2范数各有什么特点以及相应的原因？L1和L2的区别与应用场景；"></a>三、L1和L2范数各有什么特点以及相应的原因？L1和L2的区别与应用场景；</h2><p><strong>区别</strong>：L1假设参数服从拉普拉斯分布，L2则符合高斯分布；</p>
<p>L1范数更容易产生稀疏的权重，L2范数更容易产生分散的权重。</p>
<p><strong>原因</strong>：（L1稀疏的原因，L2不稀疏的原因）【几何、公式两个角度】</p>
<p><strong>场景</strong>：具有高维的数据特征时采用L1正则效果好一点。因为L1具有稀疏性。</p>
<h2 id="四、解释L1范数更容易产生稀疏的权重，L2不的原因："><a href="#四、解释L1范数更容易产生稀疏的权重，L2不的原因：" class="headerlink" title="四、解释L1范数更容易产生稀疏的权重，L2不的原因："></a>四、解释L1范数更容易产生稀疏的权重，L2不的原因：</h2><h3 id="（1）几何角度"><a href="#（1）几何角度" class="headerlink" title="（1）几何角度"></a>（1）几何角度</h3><p>L2正则项约束后的解空间是圆形，L1正则项约束后的解空间是多方形，L1易在角点发生交点，从而产生稀疏解。</p>
<blockquote>
<p>绿色等高线代表未施加正则化的代价函数，菱形和圆形分别代表L1和L2正则化约束，L1-ball 与L2-ball的不同就在于L1在和每个坐标轴相交的地方都有“角”出现，而目标函数的”等高线”除非位置摆得非常好，大部分时候都会在角的地方相交。注意到在角的位置就会产生稀疏性。相比之下，L2-ball 就没有这样的性质，因为没有角，所以第一次相交的地方出现在具有稀疏性的位置的概率就变得非常小</p>
</blockquote>
<p><img src="..\imgs\L1正则解释.jpg" alt></p>
<h3 id="（2）公式角度：（拉格朗日求导）"><a href="#（2）公式角度：（拉格朗日求导）" class="headerlink" title="（2）公式角度：（拉格朗日求导）"></a>（2）公式角度：（拉格朗日求导）</h3><blockquote>
<p>深度学习花书7.1节（202页左右）。带L1正则化的最优参数w=sign(w<em>) max{|w</em>|- a/H , 0}，其中w代表未正则化的目标函数的最优参数，H代表海森矩阵，a是正则化系数，只要a足够大，w就会在更大区间范围内使w变为0，而带L2正则化的最优参数w=H/(H+a)▪w,只要w不为0，w也不为0.</p>
</blockquote>
<p><strong>1、稀疏性的约束：</strong></p>
<p><img src="..\imgs\正则公式1.jpg" alt></p>
<p>​    L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。</p>
<p><strong>2、不好求解，松弛为L1，L2：</strong></p>
<p><img src="..\imgs\正则公式2.jpg" alt></p>
<p><strong>3、拉格朗日</strong></p>
<p><img src="..\imgs\正则公式3.jpg" alt></p>
<h3 id="（3）贝叶斯先验"><a href="#（3）贝叶斯先验" class="headerlink" title="（3）贝叶斯先验"></a>（3）贝叶斯先验</h3><blockquote>
<p>L1正则化相当于对模型参数w引入了拉普拉斯先验，L2正则化相当于引入了高斯先验，而拉普拉斯先验使参数为0的可能性更大。</p>
</blockquote>
<p><strong>L1正则化可通过假设权重w的先验分布为拉普拉斯分布，由最大后验概率估计导出。</strong></p>
<p><strong>L2正则化可通过假设权重w的先验分布为高斯分布，由最大后验概率估计导出。</strong></p>
<p><strong>详细解释：</strong> <a href="https://blog.csdn.net/m0_38045485/article/details/82147817" target="_blank" rel="noopener">https://blog.csdn.net/m0_38045485/article/details/82147817</a></p>
<p><img src="..\imgs\正则公式4.jpg" alt></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/概率论1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/概率论1/" itemprop="url">概率论</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-26T00:00:00+08:00">
                2023-02-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/先导知识/" itemprop="url" rel="index">
                    <span itemprop="name">先导知识</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/先导知识/概率论基本知识/" itemprop="url" rel="index">
                    <span itemprop="name">概率论基本知识</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<h1 id="一、均值、方差、协方差"><a href="#一、均值、方差、协方差" class="headerlink" title="一、均值、方差、协方差"></a>一、均值、方差、协方差</h1><ul>
<li>期望/均值：实验中每次可能结果的概率乘其结果的总和。<ul>
<li>E(X)=∑xP(X), x表示随机变量的取值，P(X)表示随机变量X=x的概率。</li>
</ul>
</li>
<li>方差：概率分布的数据期望，反映了随机变量取值的变异程度。<ul>
<li>D(x ) = E{[X-E(X)]^2} =E(X^2) - [ E(X)]^2</li>
</ul>
</li>
</ul>
<p><img src="..\imgs\协方差.jpg" alt></p>
<ul>
<li>协方差：度量两个随机变量关系的统计量<ul>
<li><img src="..\imgs\协方差2.jpg" alt></li>
</ul>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/过拟合欠拟合/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/过拟合欠拟合/" itemprop="url">过拟合</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-26T00:00:00+08:00">
                2023-02-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/过拟合/" itemprop="url" rel="index">
                    <span itemprop="name">过拟合</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<h1 id="过拟合"><a href="#过拟合" class="headerlink" title="过拟合"></a>过拟合</h1><h1 id="一、概念"><a href="#一、概念" class="headerlink" title="一、概念"></a>一、概念</h1><blockquote>
<p>过拟合：模型对于训练数拟合呈过当的情况，反映到评估指标上，就是模型在训练集上表现很好，测试集和新数据上表现较差。</p>
<p>欠拟合：模型在训练和和预测时表现都不好的情况。</p>
</blockquote>
<p><img src="..\imgs\过拟合欠拟合.jpg" alt></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/标准化/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/标准化/" itemprop="url">标准化</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-26T00:00:00+08:00">
                2023-02-26
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/标准化/" itemprop="url" rel="index">
                    <span itemprop="name">标准化</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<h2 id="一、BN批标准化"><a href="#一、BN批标准化" class="headerlink" title="一、BN批标准化"></a>一、BN批标准化</h2><h3 id="1、BN的基本动机"><a href="#1、BN的基本动机" class="headerlink" title="1、BN的基本动机"></a>1、BN的基本动机</h3><ol>
<li><strong>（初始数据分布一致）</strong>神经网络训练过程的本质是学习数据分布，如果训练数据与测试数据的分布      不同将大大降低网络的泛化能力，因此我们需要在训练开始前对所有输入数据进行归一化处理。</li>
<li><strong>（中间数据分布一致）</strong>然而随着网络训练的进行，每个隐层的参数变化使得后一层的输入发生变      化，从而每一批训练数据的分布也随之改变，致使网络在每次迭代中都需要拟合 不同的数据分布，增大训练的复杂度以及过拟合的风险。</li>
</ol>
<p>原因在于神经网络学习过程<strong>本质上是为了学习数据的分布</strong>，一旦训练数据与测试数据的分布不同，那么网络的泛化能力也大大降低；另一方面，一旦在mini-batch梯度下降训练的时候，每批训练数据的分布不相同，那么网络就要在每次迭代的时候去学习以适应不同的分布，这样将会大大降低网络的训练速度，这也正是为什么我们需要对所有训练数据做一个Normalization预处理的原因。</p>
<h3 id="2、-BN的原理"><a href="#2、-BN的原理" class="headerlink" title="2、 BN的原理"></a>2、 BN的原理</h3><p>BN首先是把所有的样本的统计分布标准化，降低了batch内不同样本的差异性，然后又允许batch内的各个样本有各自的统计分布。</p>
<p>BN是针对每一批数据，在网络的每一层输入之前增加归一化处理（均值为0，标准差为1），将所有批数据强制在统一的数据分布下，即对该层 的任意一个神经元（假设为第k维）x^(k) 采用如下公式:</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/广告校准/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/广告校准/" itemprop="url">广告校准</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-25T00:00:00+08:00">
                2023-02-25
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/计算广告/" itemprop="url" rel="index">
                    <span itemprop="name">计算广告</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/计算广告/校准广告/" itemprop="url" rel="index">
                    <span itemprop="name">校准广告</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<p><a href="https://zhuanlan.zhihu.com/p/460061332" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/460061332</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/582530785" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/582530785</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/398235467" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/398235467</a></p>
<h1 id="广告校准"><a href="#广告校准" class="headerlink" title="广告校准"></a>广告校准</h1><h2 id="1-业务背景"><a href="#1-业务背景" class="headerlink" title="1. 业务背景"></a>1. 业务背景</h2><blockquote>
<p>广告三大角色：广告主、媒体、DSP</p>
<ol>
<li>ctr : (Click Through Rate) 点击率 = click / show， 曝光广告中用户点击的概率。</li>
<li>cvr: (Conversion Rate) 转化率 = order / click，点击广告中用户转化的概率。（如注册，激活，创角等）</li>
<li>cpa：(Cost per Action) 转化成本 = cost / order, 表示广告主每获得一个转化需付的成本。</li>
<li>ecpm / rpm：= ctr <em> cvr </em> cpa<ol>
<li>ecpm : 对广告主来说，(Effective Cost Per Mile) 每千次展示的有效费用。 </li>
<li>rpm：对DSP来说，(Revenue Per Mile)每千次展示的收入。</li>
</ol>
</li>
<li>pctr: (Predict CTR) 预估点击率</li>
<li>pcvr: (Predict CVR) 预估转化率</li>
</ol>
</blockquote>
<h2 id="2-面临的问题"><a href="#2-面临的问题" class="headerlink" title="2. 面临的问题"></a>2. 面临的问题</h2><blockquote>
<p>（1）模型准确性存在偏差，受限于</p>
<p>​    实际分布和离线分布的差异</p>
<p>​    模型学习能力</p>
<p>（2）预估模型的准确性度量</p>
<p>​    <strong>AUC：</strong>仅作为排序指标，无法度量预估值的大小准确性</p>
<p>​    <strong>COPC：</strong>（Click On Predict Click) = sum( 实际ctr) / sum(pctr)</p>
<p>​            用于评估某段细分的流量模型预估值是否偏差较大。</p>
<p>（3）校准评价指标：</p>
<p>​    <strong>PCOC：</strong>（predict click over click）COPC是相反的指标。</p>
<p>​    <strong>cal-N：（calibration-N）</strong></p>
<p>​        cal-N将样本集合分桶后分别计算PCOC，并计算与1的偏差作为标准误差。举个例子，将pctr根据值大小划分为多个桶，每个桶为一个簇，计算每个簇的PCOC及其与1的偏差 数学公式:</p>
<p><img src="..\imgs\校准评价指标.jpg" alt></p>
<p>​    <strong>GC-N：（grouped calibration-N）</strong></p>
<p>​        在具体业务场景下，有时会重点关注某一维度下的校准效果(如广告计费维度)，GC-N可以解决这个问题，它可以在cal-N基础上自定义各维度权重。例如，下面这个式子定义了m个广告计划的GC-N 数学公式:</p>
</blockquote>
<h2 id="3-校准算法"><a href="#3-校准算法" class="headerlink" title="3. 校准算法"></a>3. 校准算法</h2><p><img src="https://pic2.zhimg.com/80/v2-c452e8c2822418e0b744fe751123b275_720w.webp" alt="img"></p>
<h3 id="（1）-Bias-Correction：负采样率修正"><a href="#（1）-Bias-Correction：负采样率修正" class="headerlink" title="（1） Bias Correction：负采样率修正"></a>（1） Bias Correction：负采样率修正</h3><blockquote>
<p><strong>原因：</strong>正负样本不均衡情况下，负采样通常可以提升模型的AUC精度，但pctr值会发生变化，与真实差距扩大。</p>
<p><strong>校准公式：</strong></p>
<p><img src="..\imgs\采样校准1.jpg" alt></p>
<p>因此可以计算出校准后的bias: <strong>b′=b+log(n)</strong></p>
</blockquote>
<p><strong>代码：</strong></p>
<p>注意在导出模型时，最终结果过完sigmoid，再进行bias_correct。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_correct</span><span class="params">(b, nr)</span>:</span></span><br><span class="line">	<span class="string">"""</span></span><br><span class="line"><span class="string">	nr: neg_sample_rate</span></span><br><span class="line"><span class="string">	</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">    <span class="keyword">if</span> nr &lt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> b + math.log(nr)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> b</span><br><span class="line"></span><br><span class="line">nr = <span class="number">0.1</span> <span class="comment"># 负采样率</span></span><br><span class="line">last_op[<span class="string">'bias'</span>] = bias_correct(last_op[<span class="string">'bias'</span>]， nr) <span class="comment"># 纠正sigmoid后的bias</span></span><br></pre></td></tr></table></figure>
<h3 id="（2）校准算法—保序回归"><a href="#（2）校准算法—保序回归" class="headerlink" title="（2）校准算法—保序回归"></a>（2）校准算法—保序回归</h3><blockquote>
<p>解决模型高低估、模型over-confidence等问题。</p>
</blockquote>
<p><img src="..\imgs\保序回归.jpg" alt></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_sir_calibration_model</span><span class="params">(pctr_list = [<span class="number">0.01</span>,<span class="number">0.02</span>,<span class="number">0.03</span>,<span class="number">0.04</span>], ctr_list = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>], bin_size = <span class="number">0.01</span>)</span>:</span></span><br><span class="line">	sort_ctr_list = sorted(list(zip(pctr_list, ctr_list)), key = <span class="keyword">lambda</span> x:x[<span class="number">0</span>])</span><br><span class="line">    bin_index = <span class="number">0</span></span><br><span class="line">    ind = <span class="number">0</span></span><br><span class="line">    n = len(ctr_list)</span><br><span class="line">    cctr_res = []</span><br><span class="line">    <span class="keyword">while</span> ind &lt; n:</span><br><span class="line">        <span class="keyword">while</span> (bin_index + bin_size) &lt; sort_ctr_list[ind][<span class="number">0</span>]:</span><br><span class="line">            cctr_res.append(sort_ctr_list[ind][<span class="number">1</span>])</span><br><span class="line">            bin_index += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> (bin_index + bin_size) == sort_ctr_list[ind][<span class="number">0</span>]:</span><br><span class="line">            cctr_res.append(sort_ctr_list[ind][<span class="number">1</span>])</span><br><span class="line">            ind += <span class="number">1</span></span><br><span class="line">            bin_index += bin_size</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">if</span> ind + <span class="number">1</span>== n:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        tmp_cctr = sort_ctr_list[ind + <span class="number">1</span>][<span class="number">1</span>]</span><br><span class="line">        tmp_num = <span class="number">1</span></span><br><span class="line">        <span class="keyword">while</span> ind + <span class="number">1</span> &lt; n <span class="keyword">and</span> bin_index + bin_size &gt; sort_ctr_list[ind][<span class="number">0</span>]:</span><br><span class="line">            tmp_cctr += sort_ctr_list[ind][<span class="number">1</span>]</span><br><span class="line">            tmp_num += <span class="number">1</span></span><br><span class="line">            ind += <span class="number">1</span></span><br><span class="line">        cctr_res.append(tmp_cctr/tmp_num)</span><br><span class="line">        bin_index += bin_size</span><br></pre></td></tr></table></figure>
<h3 id="（3）校准算法3-—-SIR（保序回归平滑校准算法）"><a href="#（3）校准算法3-—-SIR（保序回归平滑校准算法）" class="headerlink" title="（3）校准算法3 —-SIR（保序回归平滑校准算法）"></a>（3）校准算法3 —-SIR（保序回归平滑校准算法）</h3><blockquote>
<p>解决桶间数据稀疏问题</p>
</blockquote>
<p><img src="..\imgs\保序回归平滑校准1.jpg" alt></p>
<blockquote>
<p> SIR算法是18年提出的，如上图所示，结合了Binning、Isotonic Regression和线性Scaling方法。</p>
</blockquote>
<p>具体思想为：</p>
<ol>
<li><p>进行保序回归。</p>
</li>
<li><p>使用单调平滑函数拟合模型预估值和实际点击率的映射关系（线性Scaling）就得到了校准函数。</p>
</li>
</ol>
<p>该算法的优势在于充分利用了<strong>保序和平滑</strong>思想缓解了<strong>数据稀疏</strong>的问题。</p>
<p>（详细可见论文：﻿Calibrating user response predictions in online advertising）。</p>
<h3 id="（4）校准算法4—贝叶斯平滑SIR校准算法（Bayes-SIR"><a href="#（4）校准算法4—贝叶斯平滑SIR校准算法（Bayes-SIR" class="headerlink" title="（4）校准算法4—贝叶斯平滑SIR校准算法（Bayes-SIR)"></a>（4）校准算法4—贝叶斯平滑SIR校准算法（Bayes-SIR)</h3><blockquote>
<ul>
<li><p>Bayes-SIR解决冷启动问题。</p>
</li>
<li><p>beta分布：可以看作一个概率的概率分布</p>
<p><a href="https://blog.csdn.net/a358463121/article/details/52562940" target="_blank" rel="noopener">带你理解beta分布</a></p>
</li>
<li><p>贝叶斯平滑方法:（最早在雅虎的一篇论文里面中提出，用于解决数据稀疏问题下的点击率预估优化）。</p>
</li>
</ul>
</blockquote>
<p>在SIR算法应用中，发现广告计划投放初期校准效果明显差于平均水平，并在实际业务中造成以下问题：</p>
<p>1）影响新建计划初始阶段的投放表现；</p>
<p>2）影响强时效性广告的全生命周期效果；</p>
<p>3）小客户在整个投放周期里数据一直稀疏，得不到准确的校准，影响竞价公平性。</p>
<p>这是SIR校准算法的冷启动问题，采用了Bayes平滑的思想进行优化.</p>
<p><a href><img src="..\imgs\贝叶斯SIR.jpg" alt></a></p>
<p>Bayes-SIR的算法思想：如上图所示，</p>
<ol>
<li><p>从丰富的先验数据中估计出每个广告计划的点击率先验分布，</p>
</li>
<li><p>依据该先验知识求解出belta分布的参数α和β。</p>
</li>
<li>依据α和β和新观测到的少量数据，计算得到更准确的后验点击率。</li>
</ol>
<p>这种估计方法能充分利用先验知识，具备置信程度过渡平滑的特点。</p>
<p>将贝叶斯平滑CTR估计过程替换掉SIR算法的朴素CTR统计逻辑即构成了具有冷启动问题优化效果的校准方法。</p>
<p>实际上线后，新广告的投放效果得到明显的提升。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/梯度下降/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/梯度下降/" itemprop="url">梯度下降</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-21T00:00:00+08:00">
                2023-02-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/梯度下降/" itemprop="url" rel="index">
                    <span itemprop="name">梯度下降</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<p>[TOC]</p>
<h1 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h1><h2 id="1-重点"><a href="#1-重点" class="headerlink" title="1. 重点"></a>1. 重点</h2><blockquote>
<p>(1) 常用的优化方法：牛顿法、GD、拟牛顿法、共轭梯度法，之间的区别</p>
<p>(2) GD三种变形：BGD、SGD、MBGD</p>
<p>(3) 多种改进方法：Momentum、NAG、Adagrad、Adadelta、RMSProp、Adam</p>
</blockquote>
<h2 id="2-概念"><a href="#2-概念" class="headerlink" title="2. 概念"></a>2. 概念</h2><h3 id="（1）常用的优化方法：直接法、迭代法（梯度下降、牛顿法、拟牛顿法、共轭梯度法）"><a href="#（1）常用的优化方法：直接法、迭代法（梯度下降、牛顿法、拟牛顿法、共轭梯度法）" class="headerlink" title="（1）常用的优化方法：直接法、迭代法（梯度下降、牛顿法、拟牛顿法、共轭梯度法）"></a>（1）常用的优化方法：直接法、迭代法（梯度下降、牛顿法、拟牛顿法、共轭梯度法）</h3><h3 id="（2）直接法（求解析解）："><a href="#（2）直接法（求解析解）：" class="headerlink" title="（2）直接法（求解析解）："></a>（2）直接法（求解析解）：</h3><p>求梯度，令梯度为0</p>
<h3 id="（3）牛顿法："><a href="#（3）牛顿法：" class="headerlink" title="（3）牛顿法："></a>（3）牛顿法：</h3><p><img src="..\imgs\牛顿法.jpg" alt></p>
<p><img src="..\imgs\牛顿法2.jpg" alt></p>
<h3 id="（4）-GD-梯度下降"><a href="#（4）-GD-梯度下降" class="headerlink" title="（4） GD 梯度下降:"></a>（4） GD 梯度下降:</h3><p>让变量沿着目标函数负梯度的方向移动，直到移动到极小值点。</p>
<p>从拉格朗日中值定理 / 泰勒展开一阶公式都可以推出损失函数下降最大的方向是梯度方向。</p>
<p><img src="..\imgs\梯度下降方法解释.jpg" alt></p>
<p><img src="..\imgs\梯度下降方法1.jpg" alt></p>
<h2 id="3-梯度下降法和牛顿法的区别"><a href="#3-梯度下降法和牛顿法的区别" class="headerlink" title="3. 梯度下降法和牛顿法的区别"></a>3. 梯度下降法和牛顿法的区别</h2><p><strong>牛顿法和梯度下降法对比：</strong></p>
<ul>
<li><strong>从公式上看</strong>，牛顿法是二阶收敛，梯度下降是一阶收敛（局部最优），所以牛顿法就更快。</li>
</ul>
<p>【如果更通俗地说的话，比如你想找一条最短的路径走到一个盆地的最底部，梯度下降法每次只从你当前所处位置选一个坡度最大的方向走一步，牛顿法在选择方向时，不仅会考虑坡度是否够大，还会考虑你走了一步之后，坡度是否会变得更大。所以，可以说牛顿法比梯度下降法看得更远一点，能更快地走到最底部。】</p>
<ul>
<li><strong>从几何上看</strong>，牛顿法就是用一个二次曲面去拟合你当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面，通常情况下，二次曲面的拟合会比平面更好，所以牛顿法选择的下降路径会更符合真实的最优下降路径。</li>
</ul>
<h2 id="4-三种变形"><a href="#4-三种变形" class="headerlink" title="4. 三种变形"></a>4. 三种变形</h2><p>GD的三种变形：BGD、SGD、MBGD</p>
<p>这三种形式的区别就是取决于我们用多少数据来计算目标函数的梯度。</p>
<h3 id="（1）Batch-gradient-descend【批量梯度下降】"><a href="#（1）Batch-gradient-descend【批量梯度下降】" class="headerlink" title="（1）Batch gradient descend【批量梯度下降】"></a>（1）Batch gradient descend【批量梯度下降】</h3><ul>
<li><p>定义：【采用整个训练数据集的数据计算损失函数对参数的梯度】<br><img src="..\imgs\BGD.jpg" alt></p>
</li>
<li><p>优点：全局最优解；易于并行实现；</p>
</li>
<li>缺点：大样本数据计算速度非常慢，不能投入新数据实时更新模型。</li>
<li>收敛：对于凸函数可以收敛到全局最优，对于非凸函数可以收敛到局部最优。</li>
</ul>
<h3 id="（2）-Stochastic-gradient-descent【随机梯度下降】【适合在线更新】"><a href="#（2）-Stochastic-gradient-descent【随机梯度下降】【适合在线更新】" class="headerlink" title="（2） Stochastic gradient descent【随机梯度下降】【适合在线更新】"></a>（2） Stochastic gradient descent【随机梯度下降】【适合在线更新】</h3><ul>
<li>定义：SGD  每次更新时对一个样本进行梯度更新。<br> <img src="..\imgs\SGD.jpg" alt></li>
<li>优点：对于很大的数据集来说，可能会有相似的样本，这样 BGD在计算梯度时会出现冗余， 而 SGD 一次只进行一次更新，就没有冗余，而且比较快，并且可以新增样本。</li>
<li>缺点：但是 SGD 因为更新比较频繁，会造成 cost  function 有严重的震荡。准确度下降，不易于并行实现。<br> <img src="..\imgs\SGD缺点.jpg" alt></li>
<li>收敛性：不一定每次更新朝着最优值方向，因为存在噪音点，局部最优。</li>
</ul>
<h3 id="（3）mini-batch-GD【小批量梯度下降】：降低随机梯度的方差"><a href="#（3）mini-batch-GD【小批量梯度下降】：降低随机梯度的方差" class="headerlink" title="（3）mini-batch GD【小批量梯度下降】：降低随机梯度的方差"></a>（3）mini-batch GD【小批量梯度下降】：降低随机梯度的方差</h3><p>【在更新每一参数时都使用一部分样本来进行更新】</p>
<p><img src="..\imgs\MBGD&#39;.jpg" alt>‘</p>
<ul>
<li>缺点：需要指定batch大小，收敛性不好。</li>
<li>一般batch取2的幂次能充分利用矩阵运算操作（32,64,128……）</li>
<li><img src="..\imgs\MBGD.jpg" alt></li>
</ul>
<p><strong>三种方法的使用情况：</strong></p>
<p>如果样本量比较小，采用批量梯度下降算法。如果样本太大，或者在线算法，使用随机梯度下降算法。在实际的一般情况下，采用小批量梯度下降算法。</p>
<p><strong>GD具有的几个问题：</strong></p>
<p>1、学习率选择【太小，收敛速度慢，太大，在最优值附近震荡】</p>
<p>2、学习率不固定【稀疏数据，学习率可增大】</p>
<p>3、（尤其SGD）对于非凸函数，易陷于局部最优值/鞍点。</p>
<h2 id="5、优化方法"><a href="#5、优化方法" class="headerlink" title="5、优化方法"></a>5、优化方法</h2><h3 id="（1）动量Momentum【一般为SGD-momentum】"><a href="#（1）动量Momentum【一般为SGD-momentum】" class="headerlink" title="（1）动量Momentum【一般为SGD+momentum】"></a>（1）动量Momentum【一般为SGD+momentum】</h3><blockquote>
<p><strong>原理：</strong>因为SGD易陷于局部最优点或鞍点，一种帮助SGD在相关方向进行加速并抑制振荡的方法</p>
</blockquote>
<p><img src="..\imgs\Momentum_SGD.jpg" alt></p>
<p><img src="..\imgs\Momentum_SGD_1.jpg" alt></p>
<p>momentum表示要在多大程度上保留原来的更新方向，这个值在0-1之间<strong>，在训练开始时，由于梯度可能会很大，所以初始值一般选为0.5；当梯度不那么大时</strong>，一般改为0.9。<br>α是学习率，即当前batch的梯度多大程度上影响最终更新方向，跟普通的SGD含义相同。</p>
<ul>
<li>优点：因此获得了更快的收敛性和减少了震荡。</li>
<li>缺点：这种情况相当于小球从山上滚下来时是在盲目地沿着坡滚，如果它能具备一些先知，例如快要上坡时，就知道需要减速了的话，适应性会更好。</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/向量乘积/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/向量乘积/" itemprop="url">向量乘积</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-21T00:00:00+08:00">
                2023-02-21
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/先导知识/" itemprop="url" rel="index">
                    <span itemprop="name">先导知识</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/先导知识/向量乘积/" itemprop="url" rel="index">
                    <span itemprop="name">向量乘积</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<h1 id="向量乘积"><a href="#向量乘积" class="headerlink" title="向量乘积"></a>向量乘积</h1><h2 id="1-内积"><a href="#1-内积" class="headerlink" title="1. 内积"></a>1. 内积</h2><blockquote>
<p> 含义：两个向量的相似度/向量的夹角， 标量。</p>
</blockquote>
<p>向量a和向量b的余弦的相似度: 对内积进行了归一化</p>
<p>​    cosθ = 内积 / (|a| * |b| )</p>
<h2 id="2-哈达玛积"><a href="#2-哈达玛积" class="headerlink" title="2. 哈达玛积"></a>2. 哈达玛积</h2><blockquote>
<p>元素两两相乘。</p>
</blockquote>
<p>[a1, b1, c1] * [a2, b2, c2] = [a1a2, b1b2, c1c2]</p>
<p><strong>元素集的交互：</strong> [w1<em> a1a2, w2 </em> b1b2, w3 *c1c2]</p>
<p><strong>向量级别的交互：</strong>w [a1a2, b1b2, c1c2]</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/熵/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Lee_yl">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lee_yl's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/熵/" itemprop="url">熵</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2023-02-20T00:00:00+08:00">
                2023-02-20
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/先导知识/" itemprop="url" rel="index">
                    <span itemprop="name">先导知识</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/先导知识/熵/" itemprop="url" rel="index">
                    <span itemprop="name">熵</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>本篇博客仅作为学习,如有侵权必删。</p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzU0NjgzMDIxMQ==&amp;mid=2247599777&amp;idx=2&amp;sn=982e734b8de12d67ae64476c66f704bc&amp;chksm=fb54a44dcc232d5ba3fbf8f40c75801b0728beffb1b63f053b0c76209bbf54e47655dd421b25&amp;scene=27" target="_blank" rel="noopener">详解机器学习中的熵、条件熵、相对熵、交叉熵</a></p>
<h1 id="1-信息量："><a href="#1-信息量：" class="headerlink" title="1. 信息量："></a>1. 信息量：</h1><p>一个事件发生的概率越小，信息量越大，所以信息量应该为概率的<strong>减函数</strong>，对于相互独立的两个事有<em>p</em>(<em>xy</em>)=<em>p</em>(<em>x</em>)<em>p</em>(<em>y</em>)，对于这两个事件信息量应满足<em>h</em>(<em>xy</em>)=<em>h</em>(<em>x</em>)+<em>h</em>(<em>y</em>)，那么信息量应为对数函数：</p>
<p>​    h(x) = -ln p(x)</p>
<p>​    对于一个随机变量可以以不同的概率发生，那么通过<strong>信息量期望</strong>的方式衡量，即<strong>信息熵</strong>。 </p>
<h1 id="2-熵"><a href="#2-熵" class="headerlink" title="2. 熵"></a>2. 熵</h1><blockquote>
<p> 熵：信息不确定性度量（信息量与不确定性相关）。事件发生的概率越小则携带的信息越大。</p>
</blockquote>
<p>​    一个离散随机变量X的可能取值为X=x1,x2,…,xn，而对应的概率为pi=p(X=xi),则随机变量的熵定义为： </p>
<p><img src="..\imgs\熵.jpg" alt></p>
<p><img src="..\imgs\熵.jpg" style="zoom:100%"></p>
<p>​    每个<em>xi</em>表示一种特征。 <em>H</em>(<em>X</em>)在每个<em>p</em>(<em>xi</em>) = 1/<em>N</em>是最大，<em>N</em>为信息的个数。在概率为1/<em>N</em>时信息是最不确定的。</p>
<p>​    规定当p(xi)=0时，p(xi)log⁡(p(xi)=0</p>
<p>【小思考：为何公式是这样子的？其实只需熵和概率P成反比，1/P , 但是有个量纲缺点：地震发生的概率很小（P = 1/百万)，则信息量为一百万。抛硬币概率1/2，则信息量为2。两者量纲差太大，取log之后，使得低范围的值稍微放大，高范围的值稍微放小。】</p>
<h1 id="3-联合熵H-p-q"><a href="#3-联合熵H-p-q" class="headerlink" title="3. 联合熵H(p,q)"></a>3. 联合熵H(p,q)</h1><p>两个随机变量的p与q的联合分布形成的熵称为联合熵，记为<em>H</em>(p, q)。 </p>
<p><img src="..\imgs\交叉熵.jpg" style="zoom:100%"></p>
<h1 id="4-条件熵H-q-p"><a href="#4-条件熵H-q-p" class="headerlink" title="4. 条件熵H(q|p)"></a>4. 条件熵H(q|p)</h1><p><em>X</em>给定的条件下，<em>Y</em>的信息熵，即<em>H</em> (<em>Y</em> |X )。公式为：</p>
<p><img src="..\imgs\条件熵.jpg" style="zoom:100%"></p>
<p><strong>推导过程：</strong></p>
<p><img src="..\imgs\条件熵推导过程.jpg" style="zoom:100%"></p>
<h1 id="5-KL散度（相对熵）："><a href="#5-KL散度（相对熵）：" class="headerlink" title="5. KL散度（相对熵）："></a>5. KL散度（相对熵）：</h1><blockquote>
<p> 交叉熵：两个概率分布之间的一个比较，如果两个分布越匹配，交叉熵就越低；如果两个概率分布完全比配，那么交叉熵就为 0。</p>
</blockquote>
<p>如果是两个随机变量P,Q，且其概率分布分别为p(x),q(x),则p相对q的相对熵为：</p>
<p><img src="..\imgs\KL散度.jpg" style="zoom:100%"></p>
<h1 id="6-几种熵之间的关系："><a href="#6-几种熵之间的关系：" class="headerlink" title="6. 几种熵之间的关系："></a>6. 几种熵之间的关系：</h1><p><img src="..\imgs\熵之间的关系.jpg" style="zoom:100%"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Lee_yl</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Lee_yl</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
